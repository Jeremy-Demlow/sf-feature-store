# Kaggle Competition Example


<!-- WARNING: THIS FILE WAS AUTOGENERATED! DO NOT EDIT! -->

``` python
import os
from typing import Optional
from pathlib import Path
import logging
from datetime import datetime, timedelta

import snowflake.snowpark.functions as F
from snowflake.snowpark import Window

from snowflake_feature_store.connection import get_connection
from snowflake_feature_store.manager import FeatureStoreManager
from snowflake_feature_store.config import (
    FeatureViewConfig, FeatureConfig, RefreshConfig, 
    FeatureValidationConfig
)
from snowflake_feature_store.transforms import (
    Transform, TransformConfig, moving_agg, 
    fill_na, date_diff, CustomTransform
)
from snowflake_feature_store.examples import (
    get_example_data, create_feature_configs
)
from snowflake_feature_store.logging import logger
```

``` python
# Connect to Snowflake and create feature store
conn = get_connection(
    database="DATASCIENCE",
    schema="FEATURE_STORE",
    create_objects=True
)
```

    2025-03-03 17:22:26,166 - snowflake_feature_store - INFO - No active session found, creating new connection from environment
    2025-03-03 17:22:26,878 - snowflake_feature_store - INFO - Initialized connection to "DATASCIENCE"."FEATURE_STORE"
    2025-03-03 17:22:27,778 - snowflake_feature_store - INFO - Using role: "ACCOUNTADMIN", warehouse: "CONTAINER_DEMO_WH", database: DATASCIENCE, schema: FEATURE_STORE

``` python
# Create a feature store manager
manager = FeatureStoreManager(
    connection=conn,
    overwrite=True
)
```

    2025-03-03 17:22:30,633 - snowflake_feature_store - INFO - FeatureStoreManager initialized

# 1. Define Entities

``` python
# User entity
manager.add_entity(
    name="USER",
    join_keys=["USER_ID"],
    description="Instacart users who place orders"
)

# Product entity
manager.add_entity(
    name="PRODUCT",
    join_keys=["PRODUCT_ID"],
    description="Products available in Instacart"
)

# User-Product entity
manager.add_entity(
    name="USER_PRODUCT",
    join_keys=["USER_ID", "PRODUCT_ID"],
    description="Interactions between users and products"
)
```

    /Users/jdemlow/miniconda3/envs/feature-store/lib/python3.11/site-packages/snowflake/ml/feature_store/feature_store.py:197: UserWarning: Entity USER already exists. Skip registration.
      return f(self, *args, **kargs)
    /Users/jdemlow/miniconda3/envs/feature-store/lib/python3.11/site-packages/snowflake/ml/feature_store/feature_store.py:197: UserWarning: Entity PRODUCT already exists. Skip registration.
      return f(self, *args, **kargs)
    /Users/jdemlow/miniconda3/envs/feature-store/lib/python3.11/site-packages/snowflake/ml/feature_store/feature_store.py:197: UserWarning: Entity USER_PRODUCT already exists. Skip registration.
      return f(self, *args, **kargs)

    <snowflake_feature_store.manager.FeatureStoreManager at 0x143615090>

# 2. Create base DataFrames for features

### User features

``` python
user_features_df = conn.session.sql("""
SELECT 
    USER_ID,
    COUNT(DISTINCT ORDER_ID) AS USER_TOTAL_ORDERS,
    AVG(DAYS_SINCE_PRIOR_ORDER) AS AVG_DAYS_BETWEEN_ORDERS,
    PERCENTILE_CONT(0.5) WITHIN GROUP (ORDER BY ORDER_HOUR_OF_DAY) AS TYPICAL_ORDER_HOUR,
    MODE(ORDER_DOW) AS PREFERRED_ORDER_DAY,
    AVG(BASKET_SIZE) AS AVG_BASKET_SIZE,
    COUNT(DISTINCT PRODUCT_ID) AS DISTINCT_PRODUCTS_COUNT,
    SUM(REORDERED) / NULLIF(COUNT(REORDERED), 0) AS USER_REORDER_RATE
FROM (
    SELECT 
        o.USER_ID, 
        o.ORDER_ID,
        o.ORDER_DOW,
        o.ORDER_HOUR_OF_DAY,
        o.DAYS_SINCE_PRIOR_ORDER,
        COUNT(op.PRODUCT_ID) AS BASKET_SIZE,
        op.PRODUCT_ID,
        op.REORDERED,
        DATEADD('day', o.order_dow, TO_DATE('2023-01-01')) AS synthetic_date
    FROM INSTACART_RAW.ORDERS o
    JOIN INSTACART_RAW.ORDER_PRODUCTS op ON o.ORDER_ID = op.ORDER_ID
    WHERE o.EVAL_SET = 'prior'
    GROUP BY 1, 2, 3, 4, 5, 7, 8
) user_orders
GROUP BY USER_ID
""")
```

### Product features

``` python
product_features_df = conn.session.sql("""
SELECT 
    p.PRODUCT_ID,
    p.AISLE_ID,
    p.DEPARTMENT_ID,
    COUNT(DISTINCT op.ORDER_ID) AS PRODUCT_ORDERS,
    SUM(op.REORDERED) AS PRODUCT_REORDERS,
    SUM(op.REORDERED) / NULLIF(COUNT(CASE WHEN op.REORDERED = 1 THEN 1 END), 0) AS PRODUCT_REORDER_RATE,
    AVG(op.ADD_TO_CART_ORDER) AS PRODUCT_AVG_CART_POSITION
FROM INSTACART_RAW.PRODUCTS p
JOIN INSTACART_RAW.ORDER_PRODUCTS op ON p.PRODUCT_ID = op.PRODUCT_ID
JOIN INSTACART_RAW.ORDERS o ON op.ORDER_ID = o.ORDER_ID
WHERE o.EVAL_SET = 'prior'
GROUP BY p.PRODUCT_ID, p.AISLE_ID, p.DEPARTMENT_ID
""")
```

# User-Product features

``` python
user_product_features_df = conn.session.sql("""
WITH user_product_history AS (
    SELECT 
        o.USER_ID,
        op.PRODUCT_ID,
        o.ORDER_ID,
        o.ORDER_NUMBER,
        o.ORDER_DOW,
        o.ORDER_HOUR_OF_DAY,
        op.REORDERED,
        op.ADD_TO_CART_ORDER,
        ROW_NUMBER() OVER (PARTITION BY o.USER_ID, op.PRODUCT_ID ORDER BY o.ORDER_NUMBER DESC) AS rn,
        COUNT(*) OVER (PARTITION BY o.USER_ID, op.PRODUCT_ID) AS UP_ORDERS,
        AVG(op.ADD_TO_CART_ORDER) OVER (PARTITION BY o.USER_ID, op.PRODUCT_ID) AS UP_AVG_CART_POSITION
    FROM INSTACART_RAW.ORDERS o
    JOIN INSTACART_RAW.ORDER_PRODUCTS op ON o.ORDER_ID = op.ORDER_ID
    WHERE o.EVAL_SET = 'prior'
),
user_last_order AS (
    SELECT 
        USER_ID, 
        MAX(ORDER_NUMBER) AS LAST_ORDER_NUMBER
    FROM INSTACART_RAW.ORDERS
    WHERE EVAL_SET = 'prior'
    GROUP BY USER_ID
)
SELECT 
    h.USER_ID,
    h.PRODUCT_ID,
    h.ORDER_ID,
    h.ORDER_NUMBER,
    DATEADD('day', h.order_dow, TO_DATE('2023-01-01')) AS synthetic_date,
    h.ORDER_DOW,
    h.ORDER_HOUR_OF_DAY,
    h.REORDERED,
    h.UP_ORDERS,
    h.UP_AVG_CART_POSITION,
    l.LAST_ORDER_NUMBER - h.ORDER_NUMBER AS ORDERS_SINCE_LAST_PURCHASE
FROM user_product_history h
JOIN user_last_order l ON h.USER_ID = l.USER_ID
WHERE h.rn = 1
""")
```

# 3. Define Feature Configurations

``` python
# User feature configs
user_feature_configs = {
    "USER_TOTAL_ORDERS": FeatureConfig(
        name="USER_TOTAL_ORDERS",
        description="Total number of orders placed by user",
        validation=FeatureValidationConfig(null_threshold=0.0, range_check=True, min_value=1)
    ),
    "AVG_DAYS_BETWEEN_ORDERS": FeatureConfig(
        name="AVG_DAYS_BETWEEN_ORDERS",
        description="Average days between orders",
        validation=FeatureValidationConfig(null_threshold=0.1, range_check=True, min_value=0)
    ),
    "TYPICAL_ORDER_HOUR": FeatureConfig(
        name="TYPICAL_ORDER_HOUR",
        description="Median hour of day when user places orders",
        validation=FeatureValidationConfig(null_threshold=0.0, range_check=True, min_value=0, max_value=23)
    ),
    "PREFERRED_ORDER_DAY": FeatureConfig(
        name="PREFERRED_ORDER_DAY",
        description="Most common day of week for orders (0=Sunday)",
        validation=FeatureValidationConfig(null_threshold=0.0, range_check=True, min_value=0, max_value=6)
    ),
    "AVG_BASKET_SIZE": FeatureConfig(
        name="AVG_BASKET_SIZE",
        description="Average number of products per order",
        validation=FeatureValidationConfig(null_threshold=0.0, range_check=True, min_value=1)
    ),
    "DISTINCT_PRODUCTS_COUNT": FeatureConfig(
        name="DISTINCT_PRODUCTS_COUNT",
        description="Number of unique products ordered",
        validation=FeatureValidationConfig(null_threshold=0.0, range_check=True, min_value=1)
    ),
    "USER_REORDER_RATE": FeatureConfig(
        name="USER_REORDER_RATE",
        description="Proportion of products that are reordered",
        validation=FeatureValidationConfig(null_threshold=0.0, range_check=True, min_value=0, max_value=1)
    ),
    "DOMINANT_DAY_PART": FeatureConfig(
        name="DOMINANT_DAY_PART",
        description="Most common time of day for orders",
        validation=FeatureValidationConfig(null_threshold=0.1)
    )
}
```

``` python
# Product feature configs
product_feature_configs = {
    "AISLE_ID": FeatureConfig(
        name="AISLE_ID",
        description="Aisle ID for the product",
        validation=FeatureValidationConfig(null_threshold=0.0)
    ),
    "DEPARTMENT_ID": FeatureConfig(
        name="DEPARTMENT_ID",
        description="Department ID for the product",
        validation=FeatureValidationConfig(null_threshold=0.0)
    ),
    "PRODUCT_ORDERS": FeatureConfig(
        name="PRODUCT_ORDERS",
        description="Number of orders containing this product",
        validation=FeatureValidationConfig(null_threshold=0.0, range_check=True, min_value=1)
    ),
    "PRODUCT_REORDERS": FeatureConfig(
        name="PRODUCT_REORDERS",
        description="Number of times this product was reordered",
        validation=FeatureValidationConfig(null_threshold=0.0, range_check=True, min_value=0)
    ),
    "PRODUCT_REORDER_RATE": FeatureConfig(
        name="PRODUCT_REORDER_RATE",
        description="Proportion of orders that are reorders",
        validation=FeatureValidationConfig(null_threshold=0.1, range_check=True, min_value=0, max_value=1)
    ),
    "PRODUCT_AVG_CART_POSITION": FeatureConfig(
        name="PRODUCT_AVG_CART_POSITION",
        description="Average position in cart",
        validation=FeatureValidationConfig(null_threshold=0.0, range_check=True, min_value=1)
    ),
    "DEPARTMENT_POPULARITY_RANK": FeatureConfig(
        name="DEPARTMENT_POPULARITY_RANK",
        description="Popularity rank within department",
        validation=FeatureValidationConfig(null_threshold=0.1, range_check=True, min_value=1)
    ),
    "AISLE_POPULARITY_RANK": FeatureConfig(
        name="AISLE_POPULARITY_RANK",
        description="Popularity rank within aisle",
        validation=FeatureValidationConfig(null_threshold=0.1, range_check=True, min_value=1)
    )
}
```

``` python
# User-Product feature configs
user_product_feature_configs = {
    "ORDER_DOW": FeatureConfig(
        name="ORDER_DOW",
        description="Day of week for the order"
    ),
    "SYNTHETIC_DATE": FeatureConfig(
        name="SYNTHETIC_DATE",
        description="Created Date For Feature Store"
    ),
    "ORDER_HOUR_OF_DAY": FeatureConfig(
        name="ORDER_HOUR_OF_DAY",
        description="Hour of day for the order"
    ),
    "REORDERED": FeatureConfig(
        name="REORDERED",
        description="Whether the product was reordered"
    ),
    "UP_ORDERS": FeatureConfig(
        name="UP_ORDERS",
        description="Number of times user ordered this product",
        validation=FeatureValidationConfig(null_threshold=0.0, range_check=True, min_value=1)
    ),
    "UP_AVG_CART_POSITION": FeatureConfig(
        name="UP_AVG_CART_POSITION",
        description="Average cart position for this user-product",
        validation=FeatureValidationConfig(null_threshold=0.0, range_check=True, min_value=1)
    ),
    "ORDERS_SINCE_LAST_PURCHASE": FeatureConfig(
        name="ORDERS_SINCE_LAST_PURCHASE",
        description="Number of orders since user last purchased this product",
        validation=FeatureValidationConfig(null_threshold=0.1, range_check=True, min_value=0)
    ),
    "UP_ORDERS_RATIO": FeatureConfig(
        name="UP_ORDERS_RATIO",
        description="Ratio of orders containing this product to total user orders",
        validation=FeatureValidationConfig(null_threshold=0.1, range_check=True, min_value=0, max_value=1)
    ),
    "PURCHASE_RECENCY_BUCKET": FeatureConfig(
        name="PURCHASE_RECENCY_BUCKET",
        description="Recency category of last purchase (recent, medium, old)",
        validation=FeatureValidationConfig(null_threshold=0.1)
    )
}
```

# 4. Define Feature View Configs

``` python
# User feature view config
user_config = FeatureViewConfig(
    name="user_features",
    domain="INSTACART",
    entity="USER",
    feature_type="BEHAVIOR",
    refresh=RefreshConfig(frequency="1 day", mode="INCREMENTAL"),
    features=user_feature_configs,
    description="User behavior features for Instacart market basket prediction"
)
```

``` python
# Product feature view config
product_config = FeatureViewConfig(
    name="product_features",
    domain="INSTACART",
    entity="PRODUCT",
    feature_type="ATTRIBUTE",
    refresh=RefreshConfig(frequency="1 day", mode="INCREMENTAL"),
    features=product_feature_configs,
    description="Product features for Instacart market basket prediction"
)
```

``` python
# User-Product feature view config
user_product_config = FeatureViewConfig(
    name="user_product_features",
    domain="INSTACART",
    entity="USER_PRODUCT",
    feature_type="INTERACTION",
    refresh=RefreshConfig(frequency="1 day", mode="INCREMENTAL"),
    features=user_product_feature_configs,  # Updated feature configs
    description="User-product interaction features for Instacart market basket prediction"
)
```

# 5. Define Transformations

### User transformations

``` python
user_transform_config = TransformConfig(
    name="user_transforms",
    null_threshold=0.1,
    expected_types=['DECIMAL', 'DOUBLE', 'NUMBER', 'INT', 'STRING']
)

user_transforms = [
    CustomTransform(
        transform_func=lambda df: df.with_column(
            'DOMINANT_DAY_PART',
            F.when(F.col("TYPICAL_ORDER_HOUR") < 6, F.lit("night"))
             .when(F.col("TYPICAL_ORDER_HOUR") < 12, F.lit("morning"))
             .when(F.col("TYPICAL_ORDER_HOUR") < 18, F.lit("midday"))
             .otherwise(F.lit("evening"))
        ),
        config=user_transform_config
    ),
    CustomTransform(
        transform_func=lambda df: df.with_column(
            'DOMINANT_DOW',
            F.col("PREFERRED_ORDER_DAY")
        ),
        config=user_transform_config
    ),
    
    # Fill nulls in numeric columns
    fill_na(
        cols=["AVG_DAYS_BETWEEN_ORDERS", "AVG_BASKET_SIZE"],
        fill_value=0.0,
        config=user_transform_config
    )
]
```

### Product transformations

``` python
product_transform_config = TransformConfig(
    name="product_transforms",
    null_threshold=0.1,
    expected_types=['DECIMAL', 'DOUBLE', 'NUMBER', 'INT']
)

# Corrected product transforms with proper Window syntax
product_transforms = [
    # Add department popularity rank
    CustomTransform(
        transform_func=lambda df: df.with_column(
            'DEPARTMENT_POPULARITY_RANK',
            F.dense_rank().over(
                Window.partition_by("DEPARTMENT_ID").order_by(F.col("PRODUCT_ORDERS").desc())
            )
        ),
        config=product_transform_config
    ),
    
    # Add aisle popularity rank
    CustomTransform(
        transform_func=lambda df: df.with_column(
            'AISLE_POPULARITY_RANK',
            F.dense_rank().over(
                Window.partition_by("AISLE_ID").order_by(F.col("PRODUCT_ORDERS").desc())
            )
        ),
        config=product_transform_config
    )
]
```

### User-Product transformations

``` python
print("Available columns in user_product_features_df:")
print(user_product_features_df.columns)

# Now let's create a simplified version of the transforms that will work
user_product_transform_config = TransformConfig(
    name="user_product_transforms",
    null_threshold=0.1,
    expected_types=['DECIMAL', 'DOUBLE', 'NUMBER', 'INT', 'STRING']
)

user_product_transforms = [
    # Just add UP_ORDERS_RATIO column
    CustomTransform(
        transform_func=lambda df: df.with_column(
            "UP_ORDERS_RATIO", (F.col("UP_ORDERS") / F.lit(1.0))
        ),
        config=user_product_transform_config
    ),
    
    # Add PURCHASE_RECENCY_BUCKET column
    CustomTransform(
        transform_func=lambda df: df.with_column(
            "PURCHASE_RECENCY_BUCKET", 
            F.when(F.col("ORDERS_SINCE_LAST_PURCHASE") == 0, F.lit("recent"))
             .when(F.col("ORDERS_SINCE_LAST_PURCHASE") <= 3, F.lit("medium"))
             .otherwise(F.lit("old"))
        ),
        config=user_product_transform_config
    )
]
```

    Available columns in user_product_features_df:
    ['USER_ID', 'PRODUCT_ID', 'ORDER_ID', 'ORDER_NUMBER', 'SYNTHETIC_DATE', 'ORDER_DOW', 'ORDER_HOUR_OF_DAY', 'REORDERED', 'UP_ORDERS', 'UP_AVG_CART_POSITION', 'ORDERS_SINCE_LAST_PURCHASE']

# 6. Create Feature Views

``` python
user_feature_view = manager.add_feature_view(
    config=user_config,
    df=user_features_df,
    entity_name="USER",
    transforms=user_transforms,
    collect_stats=True
)
```

    Input value type doesn't match the target column data type, this replacement was skipped. Column Name: "AVG_BASKET_SIZE", Type: DecimalType(36, 6), Input Value: 0.0, Type: <class 'str'>

    2025-03-03 17:31:53,939 - snowflake_feature_store - INFO - Validated feature USER_TOTAL_ORDERS (stats: {'timestamp': '2025-03-04T01:31:43.864602', 'row_count': 206209, 'null_count': 0, 'null_ratio': 0.0, 'unique_count': 97, 'min_value': 3.0, 'max_value': 99.0, 'mean_value': 15.590367, 'std_value': 16.65477348990373})
    2025-03-03 17:32:03,939 - snowflake_feature_store - INFO - Validated feature AVG_DAYS_BETWEEN_ORDERS (stats: {'timestamp': '2025-03-04T01:31:54.383766', 'row_count': 206209, 'null_count': 0, 'null_ratio': 0.0, 'unique_count': 99570, 'min_value': 0.0, 'max_value': 30.0, 'mean_value': 15.469669692770578, 'std_value': 7.207435949657587})
    2025-03-03 17:32:21,807 - snowflake_feature_store - INFO - Validated feature TYPICAL_ORDER_HOUR (stats: {'timestamp': '2025-03-04T01:32:08.452892', 'row_count': 206209, 'null_count': 0, 'null_ratio': 0.0, 'unique_count': 47, 'min_value': 0.0, 'max_value': 23.0, 'mean_value': 13.52991625, 'std_value': 2.849790670923568})
    2025-03-03 17:32:36,393 - snowflake_feature_store - INFO - Validated feature PREFERRED_ORDER_DAY (stats: {'timestamp': '2025-03-04T01:32:25.326038', 'row_count': 206209, 'null_count': 0, 'null_ratio': 0.0, 'unique_count': 7, 'min_value': 0.0, 'max_value': 6.0, 'mean_value': 2.583282, 'std_value': 2.1554667707946695})
    2025-03-03 17:32:51,321 - snowflake_feature_store - INFO - Validated feature AVG_BASKET_SIZE (stats: {'timestamp': '2025-03-04T01:32:36.693819', 'row_count': 206209, 'null_count': 0, 'null_ratio': 0.0, 'unique_count': 1, 'min_value': 1.0, 'max_value': 1.0, 'mean_value': 1.0, 'std_value': 0.0})
    2025-03-03 17:33:05,243 - snowflake_feature_store - INFO - Validated feature DISTINCT_PRODUCTS_COUNT (stats: {'timestamp': '2025-03-04T01:32:54.842348', 'row_count': 206209, 'null_count': 0, 'null_ratio': 0.0, 'unique_count': 493, 'min_value': 1.0, 'max_value': 726.0, 'mean_value': 64.536238, 'std_value': 56.59233864225793})
    2025-03-03 17:33:18,875 - snowflake_feature_store - INFO - Validated feature USER_REORDER_RATE (stats: {'timestamp': '2025-03-04T01:33:08.412607', 'row_count': 206209, 'null_count': 0, 'null_ratio': 0.0, 'unique_count': 31274, 'min_value': 0.0, 'max_value': 0.989529, 'mean_value': 0.432249265439, 'std_value': 0.21214404798862493})
    2025-03-03 17:33:27,818 - snowflake_feature_store - INFO - Validated feature DOMINANT_DAY_PART (stats: {'timestamp': '2025-03-04T01:33:23.369257', 'row_count': 206209, 'null_count': 0, 'null_ratio': 0.0, 'unique_count': 4, 'min_value': None, 'max_value': None, 'mean_value': None, 'std_value': None})

    /Users/jdemlow/miniconda3/envs/feature-store/lib/python3.11/site-packages/snowflake/ml/feature_store/feature_store.py:1877: UserWarning: Your pipeline won't be incrementally refreshed due to: "Change tracking is not supported on queries containing the function 'PERCENTILE_CONT'.".
      self._check_dynamic_table_refresh_mode(feature_view_name)

``` python
product_feature_view = manager.add_feature_view(
    config=product_config,
    df=product_features_df,
    entity_name="PRODUCT",
    transforms=product_transforms,
    collect_stats=True
)
```

    2025-03-03 17:33:59,434 - snowflake_feature_store - INFO - Validated feature AISLE_ID (stats: {'timestamp': '2025-03-04T01:33:54.478943', 'row_count': 49677, 'null_count': 0, 'null_ratio': 0.0, 'unique_count': 134, 'min_value': 1.0, 'max_value': 134.0, 'mean_value': 67.769189, 'std_value': 38.317847251639805})
    2025-03-03 17:34:04,542 - snowflake_feature_store - INFO - Validated feature DEPARTMENT_ID (stats: {'timestamp': '2025-03-04T01:33:59.753146', 'row_count': 49677, 'null_count': 0, 'null_ratio': 0.0, 'unique_count': 21, 'min_value': 1.0, 'max_value': 21.0, 'mean_value': 11.727802, 'std_value': 5.8503070004915125})
    2025-03-03 17:34:14,571 - snowflake_feature_store - INFO - Validated feature PRODUCT_ORDERS (stats: {'timestamp': '2025-03-04T01:34:07.033387', 'row_count': 49677, 'null_count': 0, 'null_ratio': 0.0, 'unique_count': 4161, 'min_value': 1.0, 'max_value': 472565.0, 'mean_value': 652.907563, 'std_value': 4792.114415774002})
    2025-03-03 17:34:18,909 - snowflake_feature_store - INFO - Validated feature PRODUCT_REORDERS (stats: {'timestamp': '2025-03-04T01:34:15.722067', 'row_count': 49677, 'null_count': 0, 'null_ratio': 0.0, 'unique_count': 3134, 'min_value': 0.0, 'max_value': 398609.0, 'mean_value': 385.017936, 'std_value': 3601.7136460579427})
    2025-03-03 17:34:24,061 - snowflake_feature_store - INFO - Validated feature PRODUCT_REORDER_RATE (stats: {'timestamp': '2025-03-04T01:34:20.028942', 'row_count': 49677, 'null_count': 4372, 'null_ratio': 0.08800853513698492, 'unique_count': 2, 'min_value': 1.0, 'max_value': 1.0, 'mean_value': 1.0, 'std_value': 0.0})
    2025-03-03 17:34:28,391 - snowflake_feature_store - INFO - Validated feature PRODUCT_AVG_CART_POSITION (stats: {'timestamp': '2025-03-04T01:34:25.198282', 'row_count': 49677, 'null_count': 0, 'null_ratio': 0.0, 'unique_count': 26275, 'min_value': 1.0, 'max_value': 53.0, 'mean_value': 9.097568089015, 'std_value': 2.5512671640202638})
    2025-03-03 17:34:38,194 - snowflake_feature_store - INFO - Validated feature DEPARTMENT_POPULARITY_RANK (stats: {'timestamp': '2025-03-04T01:34:30.810365', 'row_count': 49677, 'null_count': 0, 'null_ratio': 0.0, 'unique_count': 1462, 'min_value': 1.0, 'max_value': 1462.0, 'mean_value': 692.939992, 'std_value': 393.0882567681207})
    2025-03-03 17:34:48,228 - snowflake_feature_store - INFO - Validated feature AISLE_POPULARITY_RANK (stats: {'timestamp': '2025-03-04T01:34:40.891883', 'row_count': 49677, 'null_count': 0, 'null_ratio': 0.0, 'unique_count': 646, 'min_value': 1.0, 'max_value': 646.0, 'mean_value': 180.192604, 'std_value': 127.69884932136233})

    /Users/jdemlow/miniconda3/envs/feature-store/lib/python3.11/site-packages/snowflake/ml/feature_store/feature_store.py:1877: UserWarning: Your pipeline won't be incrementally refreshed due to: "Change tracking is not supported on queries with window functions that have disjoint partition keys.".
      self._check_dynamic_table_refresh_mode(feature_view_name)

``` python
# Now try creating the feature view again
user_product_feature_view = manager.add_feature_view(
    config=user_product_config,
    df=user_product_features_df,
    entity_name="USER_PRODUCT",
    transforms=user_product_transforms,
    collect_stats=True
)
```

    2025-03-03 17:35:35,926 - snowflake_feature_store - INFO - Validated feature ORDER_DOW (stats: {'timestamp': '2025-03-04T01:35:12.678529', 'row_count': 13307953, 'null_count': 0, 'null_ratio': 0.0, 'unique_count': 7, 'min_value': 0.0, 'max_value': 6.0, 'mean_value': 2.753886, 'std_value': 2.0996980735334305})
    2025-03-03 17:35:52,093 - snowflake_feature_store - INFO - Validated feature SYNTHETIC_DATE (stats: {'timestamp': '2025-03-04T01:35:44.005099', 'row_count': 13307953, 'null_count': 0, 'null_ratio': 0.0, 'unique_count': 7, 'min_value': None, 'max_value': None, 'mean_value': None, 'std_value': None})
    2025-03-03 17:36:16,029 - snowflake_feature_store - INFO - Validated feature ORDER_HOUR_OF_DAY (stats: {'timestamp': '2025-03-04T01:35:52.431130', 'row_count': 13307953, 'null_count': 0, 'null_ratio': 0.0, 'unique_count': 24, 'min_value': 0.0, 'max_value': 23.0, 'mean_value': 13.514454, 'std_value': 4.226126358735621})
    2025-03-03 17:36:38,680 - snowflake_feature_store - INFO - Validated feature REORDERED (stats: {'timestamp': '2025-03-04T01:36:16.408837', 'row_count': 13307953, 'null_count': 0, 'null_ratio': 0.0, 'unique_count': 2, 'min_value': 0.0, 'max_value': 1.0, 'mean_value': 0.400156, 'std_value': 0.4899295867775287})
    2025-03-03 17:37:12,197 - snowflake_feature_store - INFO - Validated feature UP_ORDERS (stats: {'timestamp': '2025-03-04T01:36:47.477476', 'row_count': 13307953, 'null_count': 0, 'null_ratio': 0.0, 'unique_count': 99, 'min_value': 1.0, 'max_value': 99.0, 'mean_value': 2.437226, 'std_value': 3.5545275354117036})
    2025-03-03 17:37:48,296 - snowflake_feature_store - INFO - Validated feature UP_AVG_CART_POSITION (stats: {'timestamp': '2025-03-04T01:37:20.925876', 'row_count': 13307953, 'null_count': 0, 'null_ratio': 0.0, 'unique_count': 12379, 'min_value': 1.0, 'max_value': 145.0, 'mean_value': 9.217372202, 'std_value': 6.984274209769116})
    2025-03-03 17:38:18,408 - snowflake_feature_store - INFO - Validated feature ORDERS_SINCE_LAST_PURCHASE (stats: {'timestamp': '2025-03-04T01:37:55.863574', 'row_count': 13307953, 'null_count': 0, 'null_ratio': 0.0, 'unique_count': 99, 'min_value': 0.0, 'max_value': 98.0, 'mean_value': 9.512767, 'std_value': 13.416951404846035})
    2025-03-03 17:38:51,105 - snowflake_feature_store - INFO - Validated feature UP_ORDERS_RATIO (stats: {'timestamp': '2025-03-04T01:38:26.493033', 'row_count': 13307953, 'null_count': 0, 'null_ratio': 0.0, 'unique_count': 99, 'min_value': 1.0, 'max_value': 99.0, 'mean_value': 2.437225995613, 'std_value': 3.554527520515631})
    2025-03-03 17:39:06,630 - snowflake_feature_store - INFO - Validated feature PURCHASE_RECENCY_BUCKET (stats: {'timestamp': '2025-03-04T01:38:59.048885', 'row_count': 13307953, 'null_count': 0, 'null_ratio': 0.0, 'unique_count': 3, 'min_value': None, 'max_value': None, 'mean_value': None, 'std_value': None})

    /Users/jdemlow/miniconda3/envs/feature-store/lib/python3.11/site-packages/snowflake/ml/feature_store/feature_store.py:1877: UserWarning: Your pipeline won't be incrementally refreshed due to: "This dynamic table contains a complex query. Refresh mode has been set to FULL. If you wish to override this automatic choice, please re-create the dynamic table and specify REFRESH_MODE=INCREMENTAL. For best results, we recommend reading https://docs.snowflake.com/user-guide/dynamic-table-performance-guide before setting the refresh mode to INCREMENTAL.".
      self._check_dynamic_table_refresh_mode(feature_view_name)

# 7. Generate Training Dataset

``` python
# Create spine for training data
spine_df = conn.session.sql("""
SELECT 
    o.USER_ID,
    op.PRODUCT_ID,
    o.ORDER_ID,
    o.ORDER_NUMBER,
    o.ORDER_DOW,
    o.ORDER_HOUR_OF_DAY,
    op.REORDERED
FROM INSTACART_RAW.ORDERS o
JOIN INSTACART_RAW.ORDER_PRODUCTS op ON o.ORDER_ID = op.ORDER_ID
WHERE o.EVAL_SET = 'train'
""")

spine_df.show(5)
```

    ------------------------------------------------------------------------------------------------------------
    |"USER_ID"  |"PRODUCT_ID"  |"ORDER_ID"  |"ORDER_NUMBER"  |"ORDER_DOW"  |"ORDER_HOUR_OF_DAY"  |"REORDERED"  |
    ------------------------------------------------------------------------------------------------------------
    |112108     |49302         |1           |4               |4            |10                   |1            |
    |112108     |11109         |1           |4               |4            |10                   |1            |
    |112108     |10246         |1           |4               |4            |10                   |0            |
    |112108     |49683         |1           |4               |4            |10                   |0            |
    |112108     |43633         |1           |4               |4            |10                   |1            |
    ------------------------------------------------------------------------------------------------------------

``` python
# Generate training dataset with all features
training_data = manager.get_features(
    spine_df=spine_df,
    feature_views=[user_config, product_config, user_product_config],
    label_cols=["REORDERED"],
    spine_timestamp_col=None  # No timestamp needed for this dataset
)
training_data.show(5)
```

    2025-02-28 17:46:13,023 - snowflake_feature_store - INFO - Spine DataFrame columns: ['USER_ID', 'PRODUCT_ID', 'ORDER_ID', 'ORDER_NUMBER', 'ORDER_DOW', 'ORDER_HOUR_OF_DAY', 'REORDERED']
    2025-02-28 17:46:13,024 - snowflake_feature_store - INFO - Spine DataFrame schema: StructType([StructField('USER_ID', LongType(), nullable=True), StructField('PRODUCT_ID', LongType(), nullable=True), StructField('ORDER_ID', LongType(), nullable=True), StructField('ORDER_NUMBER', LongType(), nullable=True), StructField('ORDER_DOW', LongType(), nullable=True), StructField('ORDER_HOUR_OF_DAY', LongType(), nullable=True), StructField('REORDERED', LongType(), nullable=True)])
    2025-02-28 17:46:19,091 - snowflake_feature_store - INFO - Generating dataset with name: DATASET_20250301_014619_d1812ae8
    2025-02-28 17:46:19,092 - snowflake_feature_store - INFO - Label columns: ['"REORDERED"']
    2025-02-28 17:46:19,093 - snowflake_feature_store - INFO - Timestamp column: None

    FeatureStoreException: Error generating dataset: (1300) An error occurred during dataset generation: (1304): 01bab4ea-0004-a5f9-004d-de07052ae67a: 002028 (42601): SQL compilation error:
    ambiguous column name 'ORDER_ID'.
    [0;31m---------------------------------------------------------------------------[0m
    [0;31mSnowparkSQLException[0m                      Traceback (most recent call last)
    File [0;32m~/miniconda3/envs/feature-store/lib/python3.11/site-packages/snowflake/ml/feature_store/feature_store.py:1665[0m, in [0;36mFeatureStore.generate_dataset[0;34m(self, name, spine_df, features, version, spine_timestamp_col, spine_label_cols, exclude_columns, include_feature_view_timestamp_col, desc, output_type)[0m
    [1;32m   1664[0m [38;5;66;03m# TODO: Add feature store tag once Dataset (version) supports tags[39;00m
    [0;32m-> 1665[0m ds: dataset[38;5;241m.[39mDataset [38;5;241m=[39m [43mdataset[49m[38;5;241;43m.[39;49m[43mcreate_from_dataframe[49m[43m([49m
    [1;32m   1666[0m [43m    [49m[38;5;28;43mself[39;49m[38;5;241;43m.[39;49m[43m_session[49m[43m,[49m
    [1;32m   1667[0m [43m    [49m[43mname[49m[43m,[49m
    [1;32m   1668[0m [43m    [49m[43mversion[49m[43m,[49m
    [1;32m   1669[0m [43m    [49m[43minput_dataframe[49m[38;5;241;43m=[39;49m[43mresult_df[49m[43m,[49m
    [1;32m   1670[0m [43m    [49m[43mexclude_cols[49m[38;5;241;43m=[39;49m[43m[[49m[43mspine_timestamp_col[49m[43m][49m[43m [49m[38;5;28;43;01mif[39;49;00m[43m [49m[43mspine_timestamp_col[49m[43m [49m[38;5;129;43;01mis[39;49;00m[43m [49m[38;5;129;43;01mnot[39;49;00m[43m [49m[38;5;28;43;01mNone[39;49;00m[43m [49m[38;5;28;43;01melse[39;49;00m[43m [49m[43m[[49m[43m][49m[43m,[49m
    [1;32m   1671[0m [43m    [49m[43mlabel_cols[49m[38;5;241;43m=[39;49m[43mspine_label_cols[49m[43m,[49m
    [1;32m   1672[0m [43m    [49m[43mproperties[49m[38;5;241;43m=[39;49m[43mfs_meta[49m[43m,[49m
    [1;32m   1673[0m [43m    [49m[43mcomment[49m[38;5;241;43m=[39;49m[43mdesc[49m[43m,[49m
    [1;32m   1674[0m [43m[49m[43m)[49m
    [1;32m   1675[0m [38;5;28;01mreturn[39;00m ds

    File [0;32m~/miniconda3/envs/feature-store/lib/python3.11/site-packages/snowflake/ml/_internal/telemetry.py:542[0m, in [0;36msend_api_usage_telemetry.<locals>.decorator.<locals>.wrap[0;34m(*args, **kwargs)[0m
    [1;32m    541[0m [38;5;28;01mtry[39;00m:
    [0;32m--> 542[0m     [38;5;28;01mreturn[39;00m ctx[38;5;241m.[39mrun(execute_func_with_statement_params)
    [1;32m    543[0m [38;5;28;01mexcept[39;00m [38;5;167;01mException[39;00m [38;5;28;01mas[39;00m e:

    File [0;32m~/miniconda3/envs/feature-store/lib/python3.11/site-packages/snowflake/ml/_internal/telemetry.py:503[0m, in [0;36msend_api_usage_telemetry.<locals>.decorator.<locals>.wrap.<locals>.execute_func_with_statement_params[0;34m()[0m
    [1;32m    502[0m _patch_manager[38;5;241m.[39mset_statement_params(statement_params)
    [0;32m--> 503[0m result [38;5;241m=[39m [43mfunc[49m[43m([49m[38;5;241;43m*[39;49m[43margs[49m[43m,[49m[43m [49m[38;5;241;43m*[39;49m[38;5;241;43m*[39;49m[43mkwargs[49m[43m)[49m
    [1;32m    504[0m [38;5;28;01mreturn[39;00m update_stmt_params_if_snowpark_df(result, statement_params)

    File [0;32m~/miniconda3/envs/feature-store/lib/python3.11/site-packages/snowflake/ml/dataset/dataset_factory.py:33[0m, in [0;36mcreate_from_dataframe[0;34m(session, name, version, input_dataframe, **version_kwargs)[0m
    [1;32m     32[0m ds: dataset[38;5;241m.[39mDataset [38;5;241m=[39m dataset[38;5;241m.[39mDataset[38;5;241m.[39mcreate(session, name, exist_ok[38;5;241m=[39m[38;5;28;01mTrue[39;00m)
    [0;32m---> 33[0m [43mds[49m[38;5;241;43m.[39;49m[43mcreate_version[49m[43m([49m[43mversion[49m[43m,[49m[43m [49m[43minput_dataframe[49m[38;5;241;43m=[39;49m[43minput_dataframe[49m[43m,[49m[43m [49m[38;5;241;43m*[39;49m[38;5;241;43m*[39;49m[43mversion_kwargs[49m[43m)[49m
    [1;32m     34[0m ds [38;5;241m=[39m ds[38;5;241m.[39mselect_version(version)  [38;5;66;03m# select_version returns a new copy[39;00m

    File [0;32m~/miniconda3/envs/feature-store/lib/python3.11/site-packages/snowflake/ml/_internal/telemetry.py:542[0m, in [0;36msend_api_usage_telemetry.<locals>.decorator.<locals>.wrap[0;34m(*args, **kwargs)[0m
    [1;32m    541[0m [38;5;28;01mtry[39;00m:
    [0;32m--> 542[0m     [38;5;28;01mreturn[39;00m ctx[38;5;241m.[39mrun(execute_func_with_statement_params)
    [1;32m    543[0m [38;5;28;01mexcept[39;00m [38;5;167;01mException[39;00m [38;5;28;01mas[39;00m e:

    File [0;32m~/miniconda3/envs/feature-store/lib/python3.11/site-packages/snowflake/ml/_internal/telemetry.py:503[0m, in [0;36msend_api_usage_telemetry.<locals>.decorator.<locals>.wrap.<locals>.execute_func_with_statement_params[0;34m()[0m
    [1;32m    502[0m _patch_manager[38;5;241m.[39mset_statement_params(statement_params)
    [0;32m--> 503[0m result [38;5;241m=[39m [43mfunc[49m[43m([49m[38;5;241;43m*[39;49m[43margs[49m[43m,[49m[43m [49m[38;5;241;43m*[39;49m[38;5;241;43m*[39;49m[43mkwargs[49m[43m)[49m
    [1;32m    504[0m [38;5;28;01mreturn[39;00m update_stmt_params_if_snowpark_df(result, statement_params)

    File [0;32m~/miniconda3/envs/feature-store/lib/python3.11/site-packages/snowflake/ml/dataset/dataset.py:368[0m, in [0;36mDataset.create_version[0;34m(self, version, input_dataframe, shuffle, exclude_cols, label_cols, properties, partition_by, comment)[0m
    [1;32m    367[0m sql_command [38;5;241m+[39m[38;5;241m=[39m [38;5;124mf[39m[38;5;124m"[39m[38;5;124m METADATA=$$[39m[38;5;132;01m{[39;00mmetadata[38;5;241m.[39mto_json()[38;5;132;01m}[39;00m[38;5;124m$$[39m[38;5;124m"[39m
    [0;32m--> 368[0m [38;5;28;43mself[39;49m[38;5;241;43m.[39;49m[43m_session[49m[38;5;241;43m.[39;49m[43msql[49m[43m([49m[43msql_command[49m[43m)[49m[38;5;241;43m.[39;49m[43mcollect[49m[43m([49m[43mstatement_params[49m[38;5;241;43m=[39;49m[43m_TELEMETRY_STATEMENT_PARAMS[49m[43m)[49m
    [1;32m    370[0m [38;5;28;01mreturn[39;00m Dataset([38;5;28mself[39m[38;5;241m.[39m_session, [38;5;28mself[39m[38;5;241m.[39m_db, [38;5;28mself[39m[38;5;241m.[39m_schema, [38;5;28mself[39m[38;5;241m.[39m_name, version)

    File [0;32m~/miniconda3/envs/feature-store/lib/python3.11/site-packages/snowflake/snowpark/_internal/telemetry.py:174[0m, in [0;36mdf_collect_api_telemetry.<locals>.wrap[0;34m(*args, **kwargs)[0m
    [1;32m    173[0m [38;5;28;01mwith[39;00m args[[38;5;241m0[39m][38;5;241m.[39m_session[38;5;241m.[39mquery_history() [38;5;28;01mas[39;00m query_history:
    [0;32m--> 174[0m     result [38;5;241m=[39m [43mfunc[49m[43m([49m[38;5;241;43m*[39;49m[43margs[49m[43m,[49m[43m [49m[38;5;241;43m*[39;49m[38;5;241;43m*[39;49m[43mkwargs[49m[43m)[49m
    [1;32m    175[0m plan [38;5;241m=[39m args[[38;5;241m0[39m][38;5;241m.[39m_select_statement [38;5;129;01mor[39;00m args[[38;5;241m0[39m][38;5;241m.[39m_plan

    File [0;32m~/miniconda3/envs/feature-store/lib/python3.11/site-packages/snowflake/snowpark/_internal/utils.py:1029[0m, in [0;36mpublicapi.<locals>.call_wrapper[0;34m(*args, **kwargs)[0m
    [1;32m   1027[0m [38;5;66;03m# TODO: Could modify internal docstring to display that users should not modify the _emit_ast parameter.[39;00m
    [0;32m-> 1029[0m [38;5;28;01mreturn[39;00m [43mfunc[49m[43m([49m[38;5;241;43m*[39;49m[43margs[49m[43m,[49m[43m [49m[38;5;241;43m*[39;49m[38;5;241;43m*[39;49m[43mkwargs[49m[43m)[49m

    File [0;32m~/miniconda3/envs/feature-store/lib/python3.11/site-packages/snowflake/snowpark/dataframe.py:713[0m, in [0;36mDataFrame.collect[0;34m(self, statement_params, block, log_on_exception, case_sensitive, _emit_ast)[0m
    [1;32m    712[0m [38;5;28;01mwith[39;00m open_telemetry_context_manager([38;5;28mself[39m[38;5;241m.[39mcollect, [38;5;28mself[39m):
    [0;32m--> 713[0m     [38;5;28;01mreturn[39;00m [38;5;28;43mself[39;49m[38;5;241;43m.[39;49m[43m_internal_collect_with_tag_no_telemetry[49m[43m([49m
    [1;32m    714[0m [43m        [49m[43mstatement_params[49m[38;5;241;43m=[39;49m[43mstatement_params[49m[43m,[49m
    [1;32m    715[0m [43m        [49m[43mblock[49m[38;5;241;43m=[39;49m[43mblock[49m[43m,[49m
    [1;32m    716[0m [43m        [49m[43mlog_on_exception[49m[38;5;241;43m=[39;49m[43mlog_on_exception[49m[43m,[49m
    [1;32m    717[0m [43m        [49m[43mcase_sensitive[49m[38;5;241;43m=[39;49m[43mcase_sensitive[49m[43m,[49m
    [1;32m    718[0m [43m        [49m[38;5;241;43m*[39;49m[38;5;241;43m*[39;49m[43mkwargs[49m[43m,[49m
    [1;32m    719[0m [43m    [49m[43m)[49m

    File [0;32m~/miniconda3/envs/feature-store/lib/python3.11/site-packages/snowflake/snowpark/dataframe.py:784[0m, in [0;36mDataFrame._internal_collect_with_tag_no_telemetry[0;34m(self, statement_params, block, data_type, log_on_exception, case_sensitive, **kwargs)[0m
    [1;32m    771[0m [38;5;28;01mdef[39;00m[38;5;250m [39m[38;5;21m_internal_collect_with_tag_no_telemetry[39m(
    [1;32m    772[0m     [38;5;28mself[39m,
    [1;32m    773[0m     [38;5;241m*[39m,
    [0;32m   (...)[0m
    [1;32m    782[0m     [38;5;66;03m# we should always call this method instead of collect(), to make sure the[39;00m
    [1;32m    783[0m     [38;5;66;03m# query tag is set properly.[39;00m
    [0;32m--> 784[0m     [38;5;28;01mreturn[39;00m [38;5;28;43mself[39;49m[38;5;241;43m.[39;49m[43m_session[49m[38;5;241;43m.[39;49m[43m_conn[49m[38;5;241;43m.[39;49m[43mexecute[49m[43m([49m
    [1;32m    785[0m [43m        [49m[38;5;28;43mself[39;49m[38;5;241;43m.[39;49m[43m_plan[49m[43m,[49m
    [1;32m    786[0m [43m        [49m[43mblock[49m[38;5;241;43m=[39;49m[43mblock[49m[43m,[49m
    [1;32m    787[0m [43m        [49m[43mdata_type[49m[38;5;241;43m=[39;49m[43mdata_type[49m[43m,[49m
    [1;32m    788[0m [43m        [49m[43m_statement_params[49m[38;5;241;43m=[39;49m[43mcreate_or_update_statement_params_with_query_tag[49m[43m([49m
    [1;32m    789[0m [43m            [49m[43mstatement_params[49m[43m [49m[38;5;129;43;01mor[39;49;00m[43m [49m[38;5;28;43mself[39;49m[38;5;241;43m.[39;49m[43m_statement_params[49m[43m,[49m
    [1;32m    790[0m [43m            [49m[38;5;28;43mself[39;49m[38;5;241;43m.[39;49m[43m_session[49m[38;5;241;43m.[39;49m[43mquery_tag[49m[43m,[49m
    [1;32m    791[0m [43m            [49m[43mSKIP_LEVELS_THREE[49m[43m,[49m
    [1;32m    792[0m [43m        [49m[43m)[49m[43m,[49m
    [1;32m    793[0m [43m        [49m[43mlog_on_exception[49m[38;5;241;43m=[39;49m[43mlog_on_exception[49m[43m,[49m
    [1;32m    794[0m [43m        [49m[43mcase_sensitive[49m[38;5;241;43m=[39;49m[43mcase_sensitive[49m[43m,[49m
    [1;32m    795[0m [43m        [49m[38;5;241;43m*[39;49m[38;5;241;43m*[39;49m[43mkwargs[49m[43m,[49m
    [1;32m    796[0m [43m    [49m[43m)[49m

    File [0;32m~/miniconda3/envs/feature-store/lib/python3.11/site-packages/snowflake/snowpark/_internal/server_connection.py:609[0m, in [0;36mServerConnection.execute[0;34m(self, plan, to_pandas, to_iter, block, data_type, log_on_exception, case_sensitive, **kwargs)[0m
    [1;32m    606[0m     [38;5;28;01mraise[39;00m [38;5;167;01mNotImplementedError[39;00m(
    [1;32m    607[0m         [38;5;124m"[39m[38;5;124mAsync query is not supported in stored procedure yet[39m[38;5;124m"[39m
    [1;32m    608[0m     )
    [0;32m--> 609[0m result_set, result_meta [38;5;241m=[39m [38;5;28;43mself[39;49m[38;5;241;43m.[39;49m[43mget_result_set[49m[43m([49m
    [1;32m    610[0m [43m    [49m[43mplan[49m[43m,[49m
    [1;32m    611[0m [43m    [49m[43mto_pandas[49m[43m,[49m
    [1;32m    612[0m [43m    [49m[43mto_iter[49m[43m,[49m
    [1;32m    613[0m [43m    [49m[38;5;241;43m*[39;49m[38;5;241;43m*[39;49m[43mkwargs[49m[43m,[49m
    [1;32m    614[0m [43m    [49m[43mblock[49m[38;5;241;43m=[39;49m[43mblock[49m[43m,[49m
    [1;32m    615[0m [43m    [49m[43mdata_type[49m[38;5;241;43m=[39;49m[43mdata_type[49m[43m,[49m
    [1;32m    616[0m [43m    [49m[43mlog_on_exception[49m[38;5;241;43m=[39;49m[43mlog_on_exception[49m[43m,[49m
    [1;32m    617[0m [43m    [49m[43mcase_sensitive[49m[38;5;241;43m=[39;49m[43mcase_sensitive[49m[43m,[49m
    [1;32m    618[0m [43m[49m[43m)[49m
    [1;32m    619[0m [38;5;28;01mif[39;00m [38;5;129;01mnot[39;00m block:

    File [0;32m~/miniconda3/envs/feature-store/lib/python3.11/site-packages/snowflake/snowpark/_internal/analyzer/snowflake_plan.py:205[0m, in [0;36mSnowflakePlan.Decorator.wrap_exception.<locals>.wrap[0;34m(*args, **kwargs)[0m
    [1;32m    202[0m ne [38;5;241m=[39m SnowparkClientExceptionMessages[38;5;241m.[39mSQL_EXCEPTION_FROM_PROGRAMMING_ERROR(
    [1;32m    203[0m     e
    [1;32m    204[0m )
    [0;32m--> 205[0m [38;5;28;01mraise[39;00m ne[38;5;241m.[39mwith_traceback(tb) [38;5;28;01mfrom[39;00m[38;5;250m [39m[38;5;28;01mNone[39;00m

    File [0;32m~/miniconda3/envs/feature-store/lib/python3.11/site-packages/snowflake/snowpark/_internal/analyzer/snowflake_plan.py:136[0m, in [0;36mSnowflakePlan.Decorator.wrap_exception.<locals>.wrap[0;34m(*args, **kwargs)[0m
    [1;32m    135[0m [38;5;28;01mtry[39;00m:
    [0;32m--> 136[0m     [38;5;28;01mreturn[39;00m [43mfunc[49m[43m([49m[38;5;241;43m*[39;49m[43margs[49m[43m,[49m[43m [49m[38;5;241;43m*[39;49m[38;5;241;43m*[39;49m[43mkwargs[49m[43m)[49m
    [1;32m    137[0m [38;5;28;01mexcept[39;00m snowflake[38;5;241m.[39mconnector[38;5;241m.[39merrors[38;5;241m.[39mProgrammingError [38;5;28;01mas[39;00m e:

    File [0;32m~/miniconda3/envs/feature-store/lib/python3.11/site-packages/snowflake/snowpark/_internal/server_connection.py:727[0m, in [0;36mServerConnection.get_result_set[0;34m(self, plan, to_pandas, to_iter, block, data_type, log_on_exception, case_sensitive, ignore_results, **kwargs)[0m
    [1;32m    726[0m     kwargs[DATAFRAME_AST_PARAMETER] [38;5;241m=[39m dataframe_ast
    [0;32m--> 727[0m result [38;5;241m=[39m [38;5;28;43mself[39;49m[38;5;241;43m.[39;49m[43mrun_query[49m[43m([49m
    [1;32m    728[0m [43m    [49m[43mfinal_query[49m[43m,[49m
    [1;32m    729[0m [43m    [49m[43mto_pandas[49m[43m,[49m
    [1;32m    730[0m [43m    [49m[43mto_iter[49m[43m [49m[38;5;129;43;01mand[39;49;00m[43m [49m[43m([49m[43mi[49m[43m [49m[38;5;241;43m==[39;49m[43m [49m[38;5;28;43mlen[39;49m[43m([49m[43mmain_queries[49m[43m)[49m[43m [49m[38;5;241;43m-[39;49m[43m [49m[38;5;241;43m1[39;49m[43m)[49m[43m,[49m
    [1;32m    731[0m [43m    [49m[43mis_ddl_on_temp_object[49m[38;5;241;43m=[39;49m[43mquery[49m[38;5;241;43m.[39;49m[43mis_ddl_on_temp_object[49m[43m,[49m
    [1;32m    732[0m [43m    [49m[43mblock[49m[38;5;241;43m=[39;49m[38;5;129;43;01mnot[39;49;00m[43m [49m[43mis_last[49m[43m,[49m
    [1;32m    733[0m [43m    [49m[43mdata_type[49m[38;5;241;43m=[39;49m[43mdata_type[49m[43m,[49m
    [1;32m    734[0m [43m    [49m[43masync_job_plan[49m[38;5;241;43m=[39;49m[43mplan[49m[43m,[49m
    [1;32m    735[0m [43m    [49m[43mlog_on_exception[49m[38;5;241;43m=[39;49m[43mlog_on_exception[49m[43m,[49m
    [1;32m    736[0m [43m    [49m[43mcase_sensitive[49m[38;5;241;43m=[39;49m[43mcase_sensitive[49m[43m,[49m
    [1;32m    737[0m [43m    [49m[43mparams[49m[38;5;241;43m=[39;49m[43mquery[49m[38;5;241;43m.[39;49m[43mparams[49m[43m,[49m
    [1;32m    738[0m [43m    [49m[43mignore_results[49m[38;5;241;43m=[39;49m[43mignore_results[49m[43m,[49m
    [1;32m    739[0m [43m    [49m[43masync_post_actions[49m[38;5;241;43m=[39;49m[43mpost_actions[49m[43m,[49m
    [1;32m    740[0m [43m    [49m[38;5;241;43m*[39;49m[38;5;241;43m*[39;49m[43mkwargs[49m[43m,[49m
    [1;32m    741[0m [43m[49m[43m)[49m
    [1;32m    742[0m placeholders[query[38;5;241m.[39mquery_id_place_holder] [38;5;241m=[39m (
    [1;32m    743[0m     result[[38;5;124m"[39m[38;5;124msfqid[39m[38;5;124m"[39m] [38;5;28;01mif[39;00m [38;5;129;01mnot[39;00m is_last [38;5;28;01melse[39;00m result[38;5;241m.[39mquery_id
    [1;32m    744[0m )

    File [0;32m~/miniconda3/envs/feature-store/lib/python3.11/site-packages/snowflake/snowpark/_internal/server_connection.py:130[0m, in [0;36mServerConnection._Decorator.wrap_exception.<locals>.wrap[0;34m(*args, **kwargs)[0m
    [1;32m    129[0m [38;5;28;01mexcept[39;00m [38;5;167;01mException[39;00m [38;5;28;01mas[39;00m ex:
    [0;32m--> 130[0m     [38;5;28;01mraise[39;00m ex

    File [0;32m~/miniconda3/envs/feature-store/lib/python3.11/site-packages/snowflake/snowpark/_internal/server_connection.py:124[0m, in [0;36mServerConnection._Decorator.wrap_exception.<locals>.wrap[0;34m(*args, **kwargs)[0m
    [1;32m    123[0m [38;5;28;01mtry[39;00m:
    [0;32m--> 124[0m     [38;5;28;01mreturn[39;00m [43mfunc[49m[43m([49m[38;5;241;43m*[39;49m[43margs[49m[43m,[49m[43m [49m[38;5;241;43m*[39;49m[38;5;241;43m*[39;49m[43mkwargs[49m[43m)[49m
    [1;32m    125[0m [38;5;28;01mexcept[39;00m ReauthenticationRequest [38;5;28;01mas[39;00m ex:

    File [0;32m~/miniconda3/envs/feature-store/lib/python3.11/site-packages/snowflake/snowpark/_internal/server_connection.py:516[0m, in [0;36mServerConnection.run_query[0;34m(self, query, to_pandas, to_iter, is_ddl_on_temp_object, block, data_type, async_job_plan, log_on_exception, case_sensitive, params, num_statements, ignore_results, async_post_actions, **kwargs)[0m
    [1;32m    515[0m         logger[38;5;241m.[39merror([38;5;124mf[39m[38;5;124m"[39m[38;5;124mFailed to execute query[39m[38;5;132;01m{[39;00mquery_id_log[38;5;132;01m}[39;00m[38;5;124m [39m[38;5;132;01m{[39;00mquery[38;5;132;01m}[39;00m[38;5;130;01m\n[39;00m[38;5;132;01m{[39;00mex[38;5;132;01m}[39;00m[38;5;124m"[39m)
    [0;32m--> 516[0m     [38;5;28;01mraise[39;00m ex
    [1;32m    518[0m [38;5;66;03m# fetch_pandas_all/batches() only works for SELECT statements[39;00m
    [1;32m    519[0m [38;5;66;03m# We call fetchall() if fetch_pandas_all/batches() fails,[39;00m
    [1;32m    520[0m [38;5;66;03m# because when the query plan has multiple queries, it will[39;00m
    [1;32m    521[0m [38;5;66;03m# have non-select statements, and it shouldn't fail if the user[39;00m
    [1;32m    522[0m [38;5;66;03m# calls to_pandas() to execute the query.[39;00m

    File [0;32m~/miniconda3/envs/feature-store/lib/python3.11/site-packages/snowflake/snowpark/_internal/server_connection.py:501[0m, in [0;36mServerConnection.run_query[0;34m(self, query, to_pandas, to_iter, is_ddl_on_temp_object, block, data_type, async_job_plan, log_on_exception, case_sensitive, params, num_statements, ignore_results, async_post_actions, **kwargs)[0m
    [1;32m    500[0m [38;5;28;01mif[39;00m block:
    [0;32m--> 501[0m     results_cursor [38;5;241m=[39m [38;5;28;43mself[39;49m[38;5;241;43m.[39;49m[43mexecute_and_notify_query_listener[49m[43m([49m
    [1;32m    502[0m [43m        [49m[43mquery[49m[43m,[49m[43m [49m[43mparams[49m[38;5;241;43m=[39;49m[43mparams[49m[43m,[49m[43m [49m[38;5;241;43m*[39;49m[38;5;241;43m*[39;49m[43mkwargs[49m
    [1;32m    503[0m [43m    [49m[43m)[49m
    [1;32m    504[0m     logger[38;5;241m.[39mdebug([38;5;124mf[39m[38;5;124m"[39m[38;5;124mExecute query [queryID: [39m[38;5;132;01m{[39;00mresults_cursor[38;5;241m.[39msfqid[38;5;132;01m}[39;00m[38;5;124m] [39m[38;5;132;01m{[39;00mquery[38;5;132;01m}[39;00m[38;5;124m"[39m)

    File [0;32m~/miniconda3/envs/feature-store/lib/python3.11/site-packages/snowflake/ml/_internal/telemetry.py:183[0m, in [0;36m_StatementParamsPatchManager._patch_with_statement_params.<locals>.wrapper[0;34m(*args, **kwargs)[0m
    [1;32m    182[0m [38;5;28;01mtry[39;00m:
    [0;32m--> 183[0m     [38;5;28;01mreturn[39;00m [43mfunc[49m[43m([49m[38;5;241;43m*[39;49m[43margs[49m[43m,[49m[43m [49m[38;5;241;43m*[39;49m[38;5;241;43m*[39;49m[43mkwargs[49m[43m)[49m
    [1;32m    184[0m [38;5;28;01mexcept[39;00m [38;5;167;01mTypeError[39;00m [38;5;28;01mas[39;00m e:

    File [0;32m~/miniconda3/envs/feature-store/lib/python3.11/site-packages/snowflake/snowpark/_internal/server_connection.py:443[0m, in [0;36mServerConnection.execute_and_notify_query_listener[0;34m(self, query, **kwargs)[0m
    [1;32m    440[0m     [38;5;28mself[39m[38;5;241m.[39mnotify_query_listeners(
    [1;32m    441[0m         QueryRecord(sfqid, err_query, [38;5;28;01mFalse[39;00m), is_error[38;5;241m=[39m[38;5;28;01mTrue[39;00m, [38;5;241m*[39m[38;5;241m*[39mnotify_kwargs
    [1;32m    442[0m     )
    [0;32m--> 443[0m     [38;5;28;01mraise[39;00m ex
    [1;32m    445[0m notify_kwargs[[38;5;124m"[39m[38;5;124mrequestId[39m[38;5;124m"[39m] [38;5;241m=[39m [38;5;28mstr[39m(results_cursor[38;5;241m.[39m_request_id)

    File [0;32m~/miniconda3/envs/feature-store/lib/python3.11/site-packages/snowflake/snowpark/_internal/server_connection.py:434[0m, in [0;36mServerConnection.execute_and_notify_query_listener[0;34m(self, query, **kwargs)[0m
    [1;32m    433[0m [38;5;28;01mtry[39;00m:
    [0;32m--> 434[0m     results_cursor [38;5;241m=[39m [38;5;28;43mself[39;49m[38;5;241;43m.[39;49m[43m_cursor[49m[38;5;241;43m.[39;49m[43mexecute[49m[43m([49m[43mquery[49m[43m,[49m[43m [49m[38;5;241;43m*[39;49m[38;5;241;43m*[39;49m[43mkwargs[49m[43m)[49m
    [1;32m    435[0m [38;5;28;01mexcept[39;00m [38;5;167;01mException[39;00m [38;5;28;01mas[39;00m ex:

    File [0;32m~/miniconda3/envs/feature-store/lib/python3.11/site-packages/snowflake/connector/cursor.py:1103[0m, in [0;36mSnowflakeCursor.execute[0;34m(self, command, params, _bind_stage, timeout, _exec_async, _no_retry, _do_reset, _put_callback, _put_azure_callback, _put_callback_output_stream, _get_callback, _get_azure_callback, _get_callback_output_stream, _show_progress_bar, _statement_params, _is_internal, _describe_only, _no_results, _is_put_get, _raise_put_get_error, _force_put_overwrite, _skip_upload_on_content_match, file_stream, num_statements, _force_qmark_paramstyle, _dataframe_ast)[0m
    [1;32m   1102[0m     error_class [38;5;241m=[39m IntegrityError [38;5;28;01mif[39;00m is_integrity_error [38;5;28;01melse[39;00m ProgrammingError
    [0;32m-> 1103[0m     [43mError[49m[38;5;241;43m.[39;49m[43merrorhandler_wrapper[49m[43m([49m[38;5;28;43mself[39;49m[38;5;241;43m.[39;49m[43mconnection[49m[43m,[49m[43m [49m[38;5;28;43mself[39;49m[43m,[49m[43m [49m[43merror_class[49m[43m,[49m[43m [49m[43merrvalue[49m[43m)[49m
    [1;32m   1104[0m [38;5;28;01mreturn[39;00m [38;5;28mself[39m

    File [0;32m~/miniconda3/envs/feature-store/lib/python3.11/site-packages/snowflake/connector/errors.py:283[0m, in [0;36mError.errorhandler_wrapper[0;34m(connection, cursor, error_class, error_value)[0m
    [1;32m    267[0m [38;5;250m[39m[38;5;124;03m"""Error handler wrapper that calls the errorhandler method.[39;00m
    [1;32m    268[0m 
    [1;32m    269[0m [38;5;124;03mArgs:[39;00m
    [0;32m   (...)[0m
    [1;32m    280[0m [38;5;124;03m    exception to the first handler in that order.[39;00m
    [1;32m    281[0m [38;5;124;03m"""[39;00m
    [0;32m--> 283[0m handed_over [38;5;241m=[39m [43mError[49m[38;5;241;43m.[39;49m[43mhand_to_other_handler[49m[43m([49m
    [1;32m    284[0m [43m    [49m[43mconnection[49m[43m,[49m
    [1;32m    285[0m [43m    [49m[43mcursor[49m[43m,[49m
    [1;32m    286[0m [43m    [49m[43merror_class[49m[43m,[49m
    [1;32m    287[0m [43m    [49m[43merror_value[49m[43m,[49m
    [1;32m    288[0m [43m[49m[43m)[49m
    [1;32m    289[0m [38;5;28;01mif[39;00m [38;5;129;01mnot[39;00m handed_over:

    File [0;32m~/miniconda3/envs/feature-store/lib/python3.11/site-packages/snowflake/connector/errors.py:338[0m, in [0;36mError.hand_to_other_handler[0;34m(connection, cursor, error_class, error_value)[0m
    [1;32m    337[0m cursor[38;5;241m.[39mmessages[38;5;241m.[39mappend((error_class, error_value))
    [0;32m--> 338[0m [43mcursor[49m[38;5;241;43m.[39;49m[43merrorhandler[49m[43m([49m[43mconnection[49m[43m,[49m[43m [49m[43mcursor[49m[43m,[49m[43m [49m[43merror_class[49m[43m,[49m[43m [49m[43merror_value[49m[43m)[49m
    [1;32m    339[0m [38;5;28;01mreturn[39;00m [38;5;28;01mTrue[39;00m

    File [0;32m~/miniconda3/envs/feature-store/lib/python3.11/site-packages/snowflake/connector/errors.py:214[0m, in [0;36mError.default_errorhandler[0;34m(connection, cursor, error_class, error_value)[0m
    [1;32m    213[0m done_format_msg [38;5;241m=[39m error_value[38;5;241m.[39mget([38;5;124m"[39m[38;5;124mdone_format_msg[39m[38;5;124m"[39m)
    [0;32m--> 214[0m [38;5;28;01mraise[39;00m error_class(
    [1;32m    215[0m     msg[38;5;241m=[39merror_value[38;5;241m.[39mget([38;5;124m"[39m[38;5;124mmsg[39m[38;5;124m"[39m),
    [1;32m    216[0m     errno[38;5;241m=[39m[38;5;28;01mNone[39;00m [38;5;28;01mif[39;00m errno [38;5;129;01mis[39;00m [38;5;28;01mNone[39;00m [38;5;28;01melse[39;00m [38;5;28mint[39m(errno),
    [1;32m    217[0m     sqlstate[38;5;241m=[39merror_value[38;5;241m.[39mget([38;5;124m"[39m[38;5;124msqlstate[39m[38;5;124m"[39m),
    [1;32m    218[0m     sfqid[38;5;241m=[39merror_value[38;5;241m.[39mget([38;5;124m"[39m[38;5;124msfqid[39m[38;5;124m"[39m),
    [1;32m    219[0m     query[38;5;241m=[39merror_value[38;5;241m.[39mget([38;5;124m"[39m[38;5;124mquery[39m[38;5;124m"[39m),
    [1;32m    220[0m     done_format_msg[38;5;241m=[39m(
    [1;32m    221[0m         [38;5;28;01mNone[39;00m [38;5;28;01mif[39;00m done_format_msg [38;5;129;01mis[39;00m [38;5;28;01mNone[39;00m [38;5;28;01melse[39;00m [38;5;28mbool[39m(done_format_msg)
    [1;32m    222[0m     ),
    [1;32m    223[0m     connection[38;5;241m=[39mconnection,
    [1;32m    224[0m     cursor[38;5;241m=[39mcursor,
    [1;32m    225[0m )

    [0;31mSnowparkSQLException[0m: (1304): 01bab4ea-0004-a5f9-004d-de07052ae67a: 002028 (42601): SQL compilation error:
    ambiguous column name 'ORDER_ID'

    The above exception was the direct cause of the following exception:

    [0;31mSnowflakeMLException[0m                      Traceback (most recent call last)
    File [0;32m~/miniconda3/envs/feature-store/lib/python3.11/site-packages/snowflake/ml/_internal/telemetry.py:542[0m, in [0;36msend_api_usage_telemetry.<locals>.decorator.<locals>.wrap[0;34m(*args, **kwargs)[0m
    [1;32m    541[0m [38;5;28;01mtry[39;00m:
    [0;32m--> 542[0m     [38;5;28;01mreturn[39;00m ctx[38;5;241m.[39mrun(execute_func_with_statement_params)
    [1;32m    543[0m [38;5;28;01mexcept[39;00m [38;5;167;01mException[39;00m [38;5;28;01mas[39;00m e:

    File [0;32m~/miniconda3/envs/feature-store/lib/python3.11/site-packages/snowflake/ml/_internal/telemetry.py:503[0m, in [0;36msend_api_usage_telemetry.<locals>.decorator.<locals>.wrap.<locals>.execute_func_with_statement_params[0;34m()[0m
    [1;32m    502[0m _patch_manager[38;5;241m.[39mset_statement_params(statement_params)
    [0;32m--> 503[0m result [38;5;241m=[39m [43mfunc[49m[43m([49m[38;5;241;43m*[39;49m[43margs[49m[43m,[49m[43m [49m[38;5;241;43m*[39;49m[38;5;241;43m*[39;49m[43mkwargs[49m[43m)[49m
    [1;32m    504[0m [38;5;28;01mreturn[39;00m update_stmt_params_if_snowpark_df(result, statement_params)

    File [0;32m~/miniconda3/envs/feature-store/lib/python3.11/site-packages/snowflake/ml/feature_store/feature_store.py:178[0m, in [0;36mswitch_warehouse.<locals>.wrapper[0;34m(self, *args, **kargs)[0m
    [1;32m    177[0m         warehouse_updated [38;5;241m=[39m [38;5;28;01mTrue[39;00m
    [0;32m--> 178[0m     [38;5;28;01mreturn[39;00m [43mf[49m[43m([49m[38;5;28;43mself[39;49m[43m,[49m[43m [49m[38;5;241;43m*[39;49m[43margs[49m[43m,[49m[43m [49m[38;5;241;43m*[39;49m[38;5;241;43m*[39;49m[43mkargs[49m[43m)[49m
    [1;32m    179[0m [38;5;28;01mfinally[39;00m:

    File [0;32m~/miniconda3/envs/feature-store/lib/python3.11/site-packages/snowflake/ml/feature_store/feature_store.py:197[0m, in [0;36mdispatch_decorator.<locals>.decorator.<locals>.wrap[0;34m(self, *args, **kargs)[0m
    [1;32m    193[0m [38;5;129m@telemetry[39m[38;5;241m.[39msend_api_usage_telemetry(project[38;5;241m=[39m_PROJECT)
    [1;32m    194[0m [38;5;129m@switch_warehouse[39m
    [1;32m    195[0m [38;5;129m@functools[39m[38;5;241m.[39mwraps(f)
    [1;32m    196[0m [38;5;28;01mdef[39;00m[38;5;250m [39m[38;5;21mwrap[39m([38;5;28mself[39m: FeatureStore, [38;5;241m/[39m, [38;5;241m*[39margs: _Args[38;5;241m.[39margs, [38;5;241m*[39m[38;5;241m*[39mkargs: _Args[38;5;241m.[39mkwargs) [38;5;241m-[39m[38;5;241m>[39m _RT:
    [0;32m--> 197[0m     [38;5;28;01mreturn[39;00m [43mf[49m[43m([49m[38;5;28;43mself[39;49m[43m,[49m[43m [49m[38;5;241;43m*[39;49m[43margs[49m[43m,[49m[43m [49m[38;5;241;43m*[39;49m[38;5;241;43m*[39;49m[43mkargs[49m[43m)[49m

    File [0;32m~/miniconda3/envs/feature-store/lib/python3.11/site-packages/snowflake/ml/feature_store/feature_store.py:1683[0m, in [0;36mFeatureStore.generate_dataset[0;34m(self, name, spine_df, features, version, spine_timestamp_col, spine_label_cols, exclude_columns, include_feature_view_timestamp_col, desc, output_type)[0m
    [1;32m   1682[0m [38;5;28;01mexcept[39;00m SnowparkSQLException [38;5;28;01mas[39;00m e:
    [0;32m-> 1683[0m     [38;5;28;01mraise[39;00m snowml_exceptions[38;5;241m.[39mSnowflakeMLException(
    [1;32m   1684[0m         error_code[38;5;241m=[39merror_codes[38;5;241m.[39mINTERNAL_SNOWPARK_ERROR,
    [1;32m   1685[0m         original_exception[38;5;241m=[39m[38;5;167;01mRuntimeError[39;00m([38;5;124mf[39m[38;5;124m"[39m[38;5;124mAn error occurred during dataset generation: [39m[38;5;132;01m{[39;00me[38;5;132;01m}[39;00m[38;5;124m.[39m[38;5;124m"[39m),
    [1;32m   1686[0m     ) [38;5;28;01mfrom[39;00m[38;5;250m [39m[38;5;21;01me[39;00m

    [0;31mSnowflakeMLException[0m: RuntimeError("(1300) An error occurred during dataset generation: (1304): 01bab4ea-0004-a5f9-004d-de07052ae67a: 002028 (42601): SQL compilation error:\nambiguous column name 'ORDER_ID'.")

    The above exception was the direct cause of the following exception:

    [0;31mRuntimeError[0m                              Traceback (most recent call last)
    File [0;32m~/github/sf-feature-store/nbs/snowflake_feature_store/manager.py:477[0m, in [0;36mFeatureStoreManager.get_features[0;34m(self, spine_df, feature_views, label_cols, dataset_name, spine_timestamp_col, **kwargs)[0m
    [1;32m    475[0m logger[38;5;241m.[39minfo([38;5;124mf[39m[38;5;124m"[39m[38;5;124mTimestamp column: [39m[38;5;132;01m{[39;00mspine_timestamp_col[38;5;132;01m}[39;00m[38;5;124m"[39m)
    [0;32m--> 477[0m dataset [38;5;241m=[39m [38;5;28;43mself[39;49m[38;5;241;43m.[39;49m[43mfeature_store[49m[38;5;241;43m.[39;49m[43mgenerate_dataset[49m[43m([49m
    [1;32m    478[0m [43m    [49m[43mname[49m[38;5;241;43m=[39;49m[43mdataset_name[49m[43m,[49m
    [1;32m    479[0m [43m    [49m[43mspine_df[49m[38;5;241;43m=[39;49m[43mspine_df[49m[43m,[49m
    [1;32m    480[0m [43m    [49m[43mfeatures[49m[38;5;241;43m=[39;49m[43mviews[49m[43m,[49m
    [1;32m    481[0m [43m    [49m[43mspine_label_cols[49m[38;5;241;43m=[39;49m[43mlabel_cols[49m[43m,[49m
    [1;32m    482[0m [43m    [49m[43mspine_timestamp_col[49m[38;5;241;43m=[39;49m[43mspine_timestamp_col[49m[43m,[49m
    [1;32m    483[0m [43m    [49m[38;5;241;43m*[39;49m[38;5;241;43m*[39;49m[43mkwargs[49m
    [1;32m    484[0m [43m[49m[43m)[49m
    [1;32m    486[0m [38;5;28;01mreturn[39;00m dataset[38;5;241m.[39mread[38;5;241m.[39mto_snowpark_dataframe()

    File [0;32m~/miniconda3/envs/feature-store/lib/python3.11/site-packages/snowflake/ml/_internal/telemetry.py:566[0m, in [0;36msend_api_usage_telemetry.<locals>.decorator.<locals>.wrap[0;34m(*args, **kwargs)[0m
    [1;32m    565[0m     [38;5;28;01melse[39;00m:
    [0;32m--> 566[0m         [38;5;28;01mraise[39;00m me[38;5;241m.[39moriginal_exception [38;5;28;01mfrom[39;00m[38;5;250m [39m[38;5;21;01me[39;00m
    [1;32m    567[0m [38;5;28;01mfinally[39;00m:

    [0;31mRuntimeError[0m: (1300) An error occurred during dataset generation: (1304): 01bab4ea-0004-a5f9-004d-de07052ae67a: 002028 (42601): SQL compilation error:
    ambiguous column name 'ORDER_ID'.

    During handling of the above exception, another exception occurred:

    [0;31mFeatureStoreException[0m                     Traceback (most recent call last)
    Cell [0;32mIn[57], line 2[0m
    [1;32m      1[0m [38;5;66;03m# Generate training dataset with all features[39;00m
    [0;32m----> 2[0m training_data [38;5;241m=[39m [43mmanager[49m[38;5;241;43m.[39;49m[43mget_features[49m[43m([49m
    [1;32m      3[0m [43m    [49m[43mspine_df[49m[38;5;241;43m=[39;49m[43mspine_df[49m[43m,[49m
    [1;32m      4[0m [43m    [49m[43mfeature_views[49m[38;5;241;43m=[39;49m[43m[[49m[43muser_config[49m[43m,[49m[43m [49m[43mproduct_config[49m[43m,[49m[43m [49m[43muser_product_config[49m[43m][49m[43m,[49m
    [1;32m      5[0m [43m    [49m[43mlabel_cols[49m[38;5;241;43m=[39;49m[43m[[49m[38;5;124;43m"[39;49m[38;5;124;43mREORDERED[39;49m[38;5;124;43m"[39;49m[43m][49m[43m,[49m
    [1;32m      6[0m [43m    [49m[43mspine_timestamp_col[49m[38;5;241;43m=[39;49m[38;5;28;43;01mNone[39;49;00m[43m  [49m[38;5;66;43;03m# No timestamp needed for this dataset[39;49;00m
    [1;32m      7[0m [43m)[49m
    [1;32m      8[0m training_data[38;5;241m.[39mshow([38;5;241m5[39m)

    File [0;32m~/github/sf-feature-store/nbs/snowflake_feature_store/manager.py:492[0m, in [0;36mFeatureStoreManager.get_features[0;34m(self, spine_df, feature_views, label_cols, dataset_name, spine_timestamp_col, **kwargs)[0m
    [1;32m    490[0m [38;5;28;01mfor[39;00m cb [38;5;129;01min[39;00m [38;5;28mself[39m[38;5;241m.[39mcallbacks:
    [1;32m    491[0m     cb[38;5;241m.[39mon_error(error_msg)
    [0;32m--> 492[0m [38;5;28;01mraise[39;00m FeatureStoreException(error_msg)

    [0;31mFeatureStoreException[0m: Error generating dataset: (1300) An error occurred during dataset generation: (1304): 01bab4ea-0004-a5f9-004d-de07052ae67a: 002028 (42601): SQL compilation error:
    ambiguous column name 'ORDER_ID'.

``` python
# 1. First, let's check the column names in each feature view DataFrame
print("User feature columns:", user_features_df.columns)
print("Product feature columns:", product_features_df.columns)
print("User-Product feature columns:", user_product_features_df.columns)
```

    User feature columns: ['USER_ID', 'USER_TOTAL_ORDERS', 'AVG_DAYS_BETWEEN_ORDERS', 'TYPICAL_ORDER_HOUR', 'PREFERRED_ORDER_DAY', 'AVG_BASKET_SIZE', 'DISTINCT_PRODUCTS_COUNT', 'USER_REORDER_RATE']
    Product feature columns: ['PRODUCT_ID', 'AISLE_ID', 'DEPARTMENT_ID', 'PRODUCT_ORDERS', 'PRODUCT_REORDERS', 'PRODUCT_REORDER_RATE', 'PRODUCT_AVG_CART_POSITION']
    User-Product feature columns: ['USER_ID', 'PRODUCT_ID', 'ORDER_ID', 'ORDER_NUMBER', 'ORDER_DOW', 'ORDER_HOUR_OF_DAY', 'REORDERED', 'UP_ORDERS', 'UP_AVG_CART_POSITION', 'ORDERS_SINCE_LAST_PURCHASE']

``` python
# Add additional basket-level features
training_data = training_data.with_columns([
    F.count("*").over(F.Window.partition_by("ORDER_ID")).alias("BASKET_SIZE"),
    F.sum(F.col("REORDERED")).over(F.Window.partition_by("USER_ID")) / 
    F.count("*").over(F.Window.partition_by("USER_ID")).alias("REORDER_RATIO"),
    F.count_distinct("AISLE_ID").over(F.Window.partition_by("ORDER_ID")).alias("UNIQUE_AISLES"),
    F.count_distinct("DEPARTMENT_ID").over(F.Window.partition_by("ORDER_ID")).alias("UNIQUE_DEPARTMENTS"),
    F.when(F.col("ORDER_HOUR_OF_DAY") < 6, F.lit("night"))
     .when(F.col("ORDER_HOUR_OF_DAY") < 12, F.lit("morning"))
     .when(F.col("ORDER_HOUR_OF_DAY") < 18, F.lit("midday"))
     .otherwise(F.lit("evening")).alias("DAY_PART")
])
```

# 8. Save the training dataset

``` python
training_data.write.mode("overwrite").save_as_table("INSTACART_FEATURES.TRAINING_DATA")
```

# 9. (Optional) Monitor Feature Drift

``` python
# Create a simple monitoring function
def check_feature_drift(manager, feature_view_name, new_data):
    """Check for feature drift in new data"""
    drift_results = manager.check_feature_drift(
        feature_view_name=feature_view_name,
        new_data=new_data
    )
    
    if drift_results:
        logger.warning(f"Drift detected in {feature_view_name}:")
        for feature, metrics in drift_results.items():
            logger.warning(f"  {feature}: {metrics}")
    else:
        logger.info(f"No significant drift detected in {feature_view_name}")
    
    return drift_results
```

``` python
# Example usage for monitoring
# check_feature_drift(manager, "user_features", new_user_data)
```

# 10. Define prediction function

``` python
def predict_next_order(user_id, model_path=None):
    """Predict items for a user's next order"""
    # Get user features
    user_features = manager.get_features(
        spine_df=conn.session.create_dataframe([[user_id]], schema=["USER_ID"]),
        feature_views=[user_config]
    )
    
    # Get user-product features for this user
    user_products = conn.session.sql(f"""
    SELECT USER_ID, PRODUCT_ID 
    FROM INSTACART_RAW.ORDER_PRODUCTS op
    JOIN INSTACART_RAW.ORDERS o ON op.ORDER_ID = o.ORDER_ID
    WHERE USER_ID = {user_id}
    """)
    
    # Get full features for user-products
    user_product_features = manager.get_features(
        spine_df=user_products,
        feature_views=[user_config, product_config, user_product_config]
    )
    
    # Load model and predict (placeholder)
    if model_path:
        # In a real implementation, you would load your trained model
        # and make predictions here
        pass
    
    # For demo, just return products with highest reorder rate
    top_products = user_product_features.sort(F.col("PRODUCT_REORDER_RATE").desc()).limit(10)
    
    return top_products
```
