{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Kaggle Competition Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import zipfile\n",
    "from snowflake.snowpark import Session\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "import os\n",
    "from kaggle.api.kaggle_api_extended import KaggleApi\n",
    "from typing import List\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class InstacartDataLoader:\n",
    "    def __init__(self, session: Session):\n",
    "        self.session = session\n",
    "        \n",
    "    def unzip_data_files(self, path: str):\n",
    "        \"\"\"Unzip all CSV files in the directory\"\"\"\n",
    "        print(\"Unzipping data files...\")\n",
    "        for file in os.listdir(path):\n",
    "            if file.endswith('.zip'):\n",
    "                zip_path = os.path.join(path, file)\n",
    "                with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
    "                    zip_ref.extractall(path)\n",
    "                print(f\"Unzipped: {file}\")\n",
    "                \n",
    "    def load_csv_to_snowflake(self, file_path: str, table_name: str, schema: str = 'INSTACART_RAW'):\n",
    "        \"\"\"Load CSV file to Snowflake table\"\"\"\n",
    "        print(f\"Loading {file_path} to {schema}.{table_name}\")\n",
    "        chunk_size = 100000\n",
    "        for chunk in pd.read_csv(file_path, chunksize=chunk_size):\n",
    "            df = self.session.create_dataframe(chunk)\n",
    "            df.write.save_as_table(f\"{schema}.{table_name}\", mode=\"append\")\n",
    "            \n",
    "    def setup_incremental_loading(self):\n",
    "        \"\"\"Setup tables for incremental loading\"\"\"\n",
    "        self.session.sql(\"\"\"\n",
    "            CREATE OR REPLACE TABLE INSTACART_RAW.ORDER_PRODUCTS_STAGE (\n",
    "                order_id INTEGER,\n",
    "                product_id INTEGER,\n",
    "                add_to_cart_order INTEGER,\n",
    "                reordered INTEGER,\n",
    "                file_name VARCHAR,\n",
    "                loaded_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP()\n",
    "            )\n",
    "        \"\"\").collect()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def download_instacart_data(path: str = \"./data\") -> List[str]:\n",
    "    \"\"\"\n",
    "    Download Instacart Market Basket Analysis data\n",
    "    \n",
    "    Args:\n",
    "        path: Directory to save the data\n",
    "        \n",
    "    Returns:\n",
    "        List of downloaded file paths\n",
    "    \n",
    "    Raises:\n",
    "        Exception: If competition rules haven't been accepted or other API errors\n",
    "    \"\"\"\n",
    "    try:\n",
    "        api = KaggleApi()\n",
    "        api.authenticate()\n",
    "        \n",
    "        # Create data directory if it doesn't exist\n",
    "        os.makedirs(path, exist_ok=True)\n",
    "        \n",
    "        # Check if we've already downloaded the data\n",
    "        zip_path = f\"{path}/instacart-market-basket-analysis.zip\"\n",
    "        if os.path.exists(zip_path):\n",
    "            print(\"Data already downloaded, using existing files...\")\n",
    "        else:\n",
    "            print(\"Downloading competition data...\")\n",
    "            try:\n",
    "                api.competition_download_files(\n",
    "                    'instacart-market-basket-analysis',\n",
    "                    path=path\n",
    "                )\n",
    "            except Exception as e:\n",
    "                if \"rules\" in str(e):\n",
    "                    raise Exception(\n",
    "                        \"Please accept the competition rules first at \"\n",
    "                        \"https://www.kaggle.com/competitions/instacart-market-basket-analysis\"\n",
    "                    ) from e\n",
    "                raise\n",
    "        \n",
    "        # Unzip if needed\n",
    "        csv_files = [f for f in os.listdir(path) if f.endswith('.csv')]\n",
    "        if not csv_files:\n",
    "            print(\"Extracting files...\")\n",
    "            import zipfile\n",
    "            with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
    "                zip_ref.extractall(path)\n",
    "        \n",
    "        # List available files\n",
    "        csv_files = [f for f in os.listdir(path) if f.endswith('.csv')]\n",
    "        print(\"\\nAvailable files:\")\n",
    "        for file in csv_files:\n",
    "            print(f\"- {file}\")\n",
    "            \n",
    "        return [os.path.join(path, f) for f in csv_files]\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error downloading data: {str(e)}\")\n",
    "        raise\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data already downloaded, using existing files...\n",
      "\n",
      "Available files:\n",
      "- sample_submission.csv\n",
      "\n",
      "Successfully downloaded 1 files\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Usage\n",
    "try:\n",
    "    files = download_instacart_data()\n",
    "    print(f\"\\nSuccessfully downloaded {len(files)} files\")\n",
    "except Exception as e:\n",
    "    print(f\"Failed to download data: {str(e)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archive:  ./data/instacart-market-basket-analysis.zip\n",
      "  inflating: ./data/sample_submission.csv  \n"
     ]
    }
   ],
   "source": [
    "! unzip -o ./data/instacart-market-basket-analysis.zip -d ./data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class InstacartDataLoader:\n",
    "    def __init__(self, session: Session, data_path: str = \"./data\"):\n",
    "        self.session = session\n",
    "        self.data_path = data_path\n",
    "        \n",
    "    @staticmethod\n",
    "    def prep_df(df):\n",
    "        \"\"\"Prepare DataFrame for Snowflake loading\"\"\"\n",
    "        df = df.reset_index(drop=True)\n",
    "        df.index = pd.RangeIndex(start=0, stop=len(df))\n",
    "        df.columns = [col.upper() for col in df.columns]\n",
    "        return df\n",
    "        \n",
    "    def load_data(self):\n",
    "        \"\"\"Load all data using Snowpark DataFrames\"\"\"\n",
    "        print(\"Loading data...\")\n",
    "        \n",
    "        # Define all tables and their primary keys\n",
    "        tables_info = {\n",
    "            \"aisles.csv\": (\"AISLES\", [\"AISLE_ID\"]),\n",
    "            \"departments.csv\": (\"DEPARTMENTS\", [\"DEPARTMENT_ID\"]),\n",
    "            \"products.csv\": (\"PRODUCTS\", [\"PRODUCT_ID\"]),\n",
    "            \"orders.csv\": (\"ORDERS\", [\"ORDER_ID\"]),\n",
    "            \"order_products__prior.csv\": (\"ORDER_PRODUCTS\", [\"ORDER_ID\", \"PRODUCT_ID\"]),\n",
    "            \"order_products__train.csv\": (\"ORDER_PRODUCTS\", [\"ORDER_ID\", \"PRODUCT_ID\"])\n",
    "        }\n",
    "        \n",
    "        # Create schema\n",
    "        self.session.sql(\"CREATE SCHEMA IF NOT EXISTS INSTACART_RAW\").collect()\n",
    "        \n",
    "        # Load each file\n",
    "        for file, (table, pk_cols) in tables_info.items():\n",
    "            print(f\"Processing {file}...\")\n",
    "            \n",
    "            # Read and prep data\n",
    "            df = self.prep_df(pd.read_csv(f\"{self.data_path}/{file}\"))\n",
    "            \n",
    "            # Create or append to table\n",
    "            mode = \"overwrite\" if not file.startswith(\"order_products\") else \"append\"\n",
    "            self.session.create_dataframe(df) \\\n",
    "                .write.mode(mode) \\\n",
    "                .save_as_table(f\"INSTACART_RAW.{table}\")\n",
    "            \n",
    "            # Add primary key if not appending\n",
    "            if mode == \"overwrite\":\n",
    "                pk_str = \", \".join(pk_cols)\n",
    "                try:\n",
    "                    self.session.sql(f\"\"\"\n",
    "                        ALTER TABLE INSTACART_RAW.{table} \n",
    "                        ADD PRIMARY KEY ({pk_str})\n",
    "                    \"\"\").collect()\n",
    "                except Exception as e:\n",
    "                    print(f\"Warning: Could not add primary key to {table}: {str(e)}\")\n",
    "    \n",
    "    def validate_load(self):\n",
    "        \"\"\"Validate the loaded data\"\"\"\n",
    "        print(\"\\nValidating loaded data...\")\n",
    "        for table in [\"AISLES\", \"DEPARTMENTS\", \"PRODUCTS\", \"ORDERS\", \"ORDER_PRODUCTS\"]:\n",
    "            count = self.session.sql(f\"SELECT COUNT(*) as cnt FROM INSTACART_RAW.{table}\").collect()[0]['CNT']\n",
    "            print(f\"{table}: {count:,} rows\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-26 19:17:16,403 - snowflake_feature_store - INFO - Using active Snowflake session\n",
      "2025-02-26 19:17:16,407 - snowflake_feature_store - INFO - Initialized connection to \"DATASCIENCE\".\"INSTACART_RAW\"\n",
      "2025-02-26 19:17:19,182 - snowflake_feature_store - INFO - Using role: \"DATA_SCIENTIST\", warehouse: \"DS_WH_XS\", database: DATASCIENCE, schema: INSTACART_RAW\n",
      "Unzipping data files...\n",
      "Unzipped: instacart-market-basket-analysis.zip\n"
     ]
    }
   ],
   "source": [
    "from snowflake_feature_store.connection import get_connection\n",
    "\n",
    "# Specify all connection parameters directly\n",
    "database = \"DATASCIENCE\"\n",
    "schema = \"INSTACART_RAW\"\n",
    "warehouse = \"DS_WH_XS\"\n",
    "role = \"DATA_SCIENTIST\"\n",
    "\n",
    "# Get connection with all custom parameters\n",
    "conn = get_connection(\n",
    "    database=database, \n",
    "    schema=schema, \n",
    "    warehouse=warehouse,\n",
    "    role=role\n",
    ")\n",
    "\n",
    "# Usage\n",
    "loader = InstacartDataLoader(conn.session)\n",
    "loader.unzip_data_files('./data/')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loader.load_data()\n",
    "loader.validate_load()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "feature-store",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
