{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Configuration\n",
    "\n",
    "> This module provides configuration classes for a feature store system. It defines a comprehensive configuration structure using Pydantic models to support feature view management with validation capabilities. The configuration includes settings for feature views, data sources, and other related components."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Hi Everyone,Â \n",
    "\n",
    "Network rules specify the external destinations (hostnames, IPs, ports) that your container service is allowed to communicate with. They define the boundaries of where your service can send network traffic. Think of them as a whitelist of destinations. The values from SYSTEM$GET_PRIVATELINK_CONFIG() are what you should be focusing on if you want to work through your privatelink connection. You have to create access points for these to work.1. First, identify exactly what your service needs:-- Get the exact PrivateLink endpoints for your accountSELECT SYSTEM$GET_PRIVATELINK_CONFIG();2. Create a targeted network rule:-- Create a network rule specifically for Snowflake's endpointsCREATE OR REPLACE NETWORK RULE jupyter_snowflake_connectivity MODE = EGRESS TYPE = PRIVATE_HOST_PORT VALUE_LIST = ( '<your-spcs-auth-privatelink-url-value>', '<your-app-service-privatelink-url-value>' );This approach only grants access to the specific Snowflake PrivateLink endpoints needed for authentication and accessing your service, rather than including S3 and PyPI which may not be required for basic functionality.3. For additional functionality:If your Jupyter service needs to access specific packages or data sources, you can create separate, purpose-specific network rules:-- Only add if your service needs to fetch packagesCREATE OR REPLACE NETWORK RULE jupyter_package_access MODE = EGRESS TYPE = HOST_PORT VALUE_LIST = ('pypi.org:443', 'files.pythonhosted.org:443');-- Only add if your service needs S3 accessCREATE OR REPLACE NETWORK RULE jupyter_s3_access MODE = EGRESS TYPE = PRIVATE_HOST_PORT VALUE_LIST = ('<your-specific-s3-bucket>.s3.<your-region>.amazonaws.com');4. Create a more targeted EAI:\n",
    "-- Include only the network rules your service actually needsCREATE OR REPLACE EXTERNAL ACCESS INTEGRATION jupyter_eai ALLOWED_NETWORK_RULES = (jupyter_snowflake_connectivity) ENABLED = true;-- If you added the optional rules above, you might use:-- ALLOWED_NETWORK_RULES = (jupyter_snowflake_connectivity, jupyter_package_access, jupyter_s3_access)This approach follows the principle of least privilege by only granting the specific access needed for the service to function, which is a security best practice.For your POC environment, you might start with just the Snowflake PrivateLink endpoints and then add additional access only if you encounter specific functionality issues."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "from __future__ import annotations\n",
    "from typing import Optional, Dict, List, Union\n",
    "from pydantic import BaseModel, Field, validator\n",
    "from datetime import timedelta\n",
    "import yaml\n",
    "from pathlib import Path\n",
    "\n",
    "# Import our custom exceptions\n",
    "from snowflake_feature_store.exceptions import ConfigurationError\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/hm/zsqyytm950g1dc_00qtbp2zh0000gn/T/ipykernel_47609/2816683478.py:7: PydanticDeprecatedSince20: Pydantic V1 style `@validator` validators are deprecated. You should migrate to Pydantic V2 style `@field_validator` validators, see the migration guide for more details. Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.10/migration/\n",
      "  @validator('frequency')\n"
     ]
    }
   ],
   "source": [
    "#| export\n",
    "class RefreshConfig(BaseModel):\n",
    "    \"\"\"Configuration for feature refresh settings\"\"\"\n",
    "    frequency: str = Field(\"1 day\", description=\"Refresh frequency (e.g., '1 day', '30 minutes')\")\n",
    "    mode: str = Field(\"FULL\", description=\"Refresh mode (FULL or INCREMENTAL)\")\n",
    "    \n",
    "    @validator('frequency')\n",
    "    def validate_frequency(cls, v):\n",
    "        \"\"\"Validate refresh frequency format\"\"\"\n",
    "        try:\n",
    "            # Check if it's a cron expression\n",
    "            if ' ' in v and len(v.split()) == 5:\n",
    "                return v\n",
    "            \n",
    "            # Parse as time duration\n",
    "            parts = v.split()\n",
    "            if len(parts) != 2:\n",
    "                raise ValueError\n",
    "            \n",
    "            num = int(parts[0])\n",
    "            unit = parts[1].lower()\n",
    "            \n",
    "            valid_units = ['minute', 'minutes', 'hour', 'hours', 'day', 'days']\n",
    "            if unit not in valid_units:\n",
    "                raise ValueError\n",
    "                \n",
    "            return v\n",
    "        except ValueError:\n",
    "            raise ConfigurationError(\n",
    "                f\"Invalid refresh frequency: {v}. \"\n",
    "                \"Use either cron expression or duration (e.g., '1 day', '30 minutes')\"\n",
    "            )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#| export\n",
    "class FeatureValidationConfig(BaseModel):\n",
    "    \"\"\"Configuration for feature validation rules\"\"\"\n",
    "    null_check: bool = Field(True, description=\"Check for null values\")\n",
    "    null_threshold: float = Field(0.1, description=\"Maximum allowed null ratio\")\n",
    "    range_check: bool = Field(False, description=\"Check value ranges\")\n",
    "    min_value: Optional[float] = None\n",
    "    max_value: Optional[float] = None\n",
    "    unique_check: bool = Field(False, description=\"Check for uniqueness\")\n",
    "    unique_threshold: float = Field(0.9, description=\"Minimum unique ratio\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#| export\n",
    "class FeatureConfig(BaseModel):\n",
    "    \"\"\"Configuration for individual features\"\"\"\n",
    "    name: str\n",
    "    description: str\n",
    "    validation: Optional[FeatureValidationConfig] = Field(\n",
    "        default_factory=FeatureValidationConfig,\n",
    "        description=\"Validation rules for this feature\"\n",
    "    )\n",
    "    dependencies: List[str] = Field(\n",
    "        default_factory=list,\n",
    "        description=\"List of features this feature depends on\"\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#| export\n",
    "class FeatureViewConfig(BaseModel):\n",
    "    \"\"\"Enhanced configuration for feature views\"\"\"\n",
    "    name: str\n",
    "    domain: str = \"\"\n",
    "    entity: str = \"CUSTOMER\"\n",
    "    feature_type: str = \"BASE\"\n",
    "    major_version: int = Field(1, ge=1)\n",
    "    minor_version: int = Field(0, ge=0)\n",
    "    refresh: RefreshConfig = Field(default_factory=RefreshConfig)\n",
    "    timestamp_col: Optional[str] = None\n",
    "    description: Optional[str] = None\n",
    "    features: Dict[str, FeatureConfig] = Field(\n",
    "        default_factory=dict,\n",
    "        description=\"Configuration for each feature\"\n",
    "    )\n",
    "    tags: Dict[str, str] = Field(default_factory=dict)\n",
    "\n",
    "    @property\n",
    "    def version(self) -> str:\n",
    "        \"\"\"Get formatted version string\"\"\"\n",
    "        return f\"V{self.major_version}_{self.minor_version}\"\n",
    "\n",
    "    @property\n",
    "    def full_name(self) -> str:\n",
    "        \"\"\"Get formatted full name for the feature view\"\"\"\n",
    "        parts = [\"FV\"]\n",
    "        if self.domain:\n",
    "            parts.append(self.domain)\n",
    "        parts.extend([self.entity, self.feature_type])\n",
    "        return \"_\".join(part.upper() for part in parts)\n",
    "    \n",
    "    @property\n",
    "    def refresh_frequency(self) -> str:\n",
    "        \"\"\"Get refresh frequency from RefreshConfig\"\"\"\n",
    "        return self.refresh.frequency\n",
    "\n",
    "    @classmethod\n",
    "    def from_yaml(cls, path: Union[str, Path]) -> FeatureViewConfig:\n",
    "        \"\"\"Load configuration from YAML file\"\"\"\n",
    "        try:\n",
    "            with open(path) as f:\n",
    "                data = yaml.safe_load(f)\n",
    "            return cls(**data)\n",
    "        except Exception as e:\n",
    "            raise ConfigurationError(f\"Error loading config from {path}: {str(e)}\")\n",
    "\n",
    "    def to_yaml(self, path: Union[str, Path]) -> None:\n",
    "        \"\"\"Save configuration to YAML file\"\"\"\n",
    "        try:\n",
    "            with open(path, 'w') as f:\n",
    "                yaml.dump(self.dict(), f)\n",
    "        except Exception as e:\n",
    "            raise ConfigurationError(f\"Error saving config to {path}: {str(e)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "import nbdev; nbdev.nbdev_export()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
