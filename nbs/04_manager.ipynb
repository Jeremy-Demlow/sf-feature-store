{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NAME\n",
    "\n",
    "> Fill in a module description here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | default_exp manager"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n"
     ]
    }
   ],
   "source": [
    "# | export\n",
    "from __future__ import annotations\n",
    "from typing import List, Optional, Dict, Union, Protocol, Callable\n",
    "from dataclasses import dataclass\n",
    "import uuid\n",
    "from contextlib import contextmanager\n",
    "from typing import Optional\n",
    "\n",
    "from snowflake.ml.feature_store import FeatureStore, Entity, FeatureView, CreationMode\n",
    "from snowflake.snowpark import DataFrame\n",
    "\n",
    "from snowflake_feature_store.connection import SnowflakeConnection\n",
    "from snowflake_feature_store.feature_view import FeatureViewConfig, create_feature_view\n",
    "from snowflake_feature_store.transforms import Transform, apply_transforms\n",
    "from datetime import datetime, timezone \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# | export\n",
    "class FeatureStoreCallback(Protocol):\n",
    "    \"Protocol for feature store callbacks\"\n",
    "    def on_feature_view_create(self, name: str, df: DataFrame) -> None: ...\n",
    "    def on_entity_create(self, name: str, keys: List[str]) -> None: ...\n",
    "    def on_error(self, error: str) -> None: ...\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# | export\n",
    "class PrintCallback:\n",
    "    \"Simple callback that prints events\"\n",
    "    def on_feature_view_create(self, name: str, df: DataFrame) -> None:\n",
    "        print(f\"Created feature view: {name} with {len(df.columns)} features\")\n",
    "    \n",
    "    def on_entity_create(self, name: str, keys: List[str]) -> None:\n",
    "        print(f\"Created entity: {name} with keys: {keys}\")\n",
    "        \n",
    "    def on_error(self, error: str) -> None:\n",
    "        print(f\"Error: {error}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# | export\n",
    "@dataclass\n",
    "class FeatureStoreManager:\n",
    "    \"\"\"Manages feature store operations\n",
    "    \n",
    "    Args:\n",
    "        connection: Snowflake connection\n",
    "        callbacks: Optional callbacks for monitoring\n",
    "        overwrite: Whether to overwrite existing features\n",
    "    \"\"\"\n",
    "    connection: SnowflakeConnection\n",
    "    callbacks: List[FeatureStoreCallback] = None\n",
    "    overwrite: bool = False\n",
    "    \n",
    "    def __post_init__(self):\n",
    "        \"Initialize feature store\"\n",
    "        self.feature_store = FeatureStore(\n",
    "            session=self.connection.session,\n",
    "            database=self.connection.database,\n",
    "            name=self.connection.schema,\n",
    "            default_warehouse=self.connection.warehouse,\n",
    "            creation_mode=CreationMode.CREATE_IF_NOT_EXIST\n",
    "        )\n",
    "        self.entities: Dict[str, Entity] = {}\n",
    "        self.feature_views: Dict[str, FeatureView] = {}\n",
    "        self.callbacks = self.callbacks or []\n",
    "        \n",
    "    def add_entity(self, \n",
    "                  name: str, \n",
    "                  join_keys: List[str], \n",
    "                  description: Optional[str] = None) -> FeatureStoreManager:\n",
    "        \"\"\"Add entity to feature store\n",
    "        \n",
    "        Args:\n",
    "            name: Entity name\n",
    "            join_keys: Keys used for joining\n",
    "            description: Optional description\n",
    "            \n",
    "        Returns:\n",
    "            Self for method chaining\n",
    "        \"\"\"\n",
    "        entity = Entity(\n",
    "            name=name,\n",
    "            join_keys=join_keys,\n",
    "            desc=description or f\"Entity {name}\"\n",
    "        )\n",
    "        try:\n",
    "            self.feature_store.register_entity(entity)\n",
    "            self.entities[name] = entity\n",
    "            for cb in self.callbacks:\n",
    "                cb.on_entity_create(name, join_keys)\n",
    "        except Exception as e:\n",
    "            for cb in self.callbacks:\n",
    "                cb.on_error(f\"Error creating entity {name}: {str(e)}\")\n",
    "            raise\n",
    "        return self\n",
    "    \n",
    "    def add_feature_view(self,\n",
    "                        config: FeatureViewConfig,\n",
    "                        df: DataFrame,\n",
    "                        entity_name: str,\n",
    "                        transforms: Optional[List[Transform]] = None) -> FeatureView:\n",
    "        \"\"\"Add feature view to feature store\"\"\"\n",
    "        try:\n",
    "            # Validate schema only (no execution)\n",
    "            self._validate_schema_only(df)\n",
    "            \n",
    "            # Apply transforms if provided\n",
    "            if transforms:\n",
    "                df = apply_transforms(df, transforms)\n",
    "            \n",
    "            self._validate_sql(df)\n",
    "                \n",
    "            # Get entity\n",
    "            entity = self.entities.get(entity_name)\n",
    "            if not entity:\n",
    "                raise ValueError(f\"Entity {entity_name} not found\")\n",
    "                \n",
    "            # Create feature view\n",
    "            feature_view = create_feature_view(config, df, entity)\n",
    "            \n",
    "            # Register feature view (this is where actual execution happens)\n",
    "            registered_view = self.feature_store.register_feature_view(\n",
    "                feature_view=feature_view,\n",
    "                version=config.version,\n",
    "                block=True,\n",
    "                overwrite=self.overwrite\n",
    "            )\n",
    "            \n",
    "            # Store for later reference\n",
    "            self.feature_views[config.full_name] = registered_view\n",
    "            \n",
    "            # Notify callbacks\n",
    "            for cb in self.callbacks:\n",
    "                cb.on_feature_view_create(config.full_name, df)\n",
    "                \n",
    "            return registered_view\n",
    "            \n",
    "        except Exception as e:\n",
    "            for cb in self.callbacks:\n",
    "                cb.on_error(f\"Error creating feature view {config.full_name}: {str(e)}\")\n",
    "            raise\n",
    "\n",
    "    def get_features(self,\n",
    "                    spine_df: DataFrame,\n",
    "                    feature_views: List[Union[str, FeatureViewConfig]],\n",
    "                    label_cols: Optional[List[str]] = None,\n",
    "                    dataset_name: Optional[str] = None,\n",
    "                    spine_timestamp_col: Optional[str] = None,\n",
    "                    **kwargs) -> DataFrame:\n",
    "        \"\"\"Get features for training or inference\"\"\"\n",
    "        views = []\n",
    "        for fv in feature_views:\n",
    "            if isinstance(fv, FeatureViewConfig):\n",
    "                view = self.feature_store.get_feature_view(\n",
    "                    fv.full_name, \n",
    "                    version=fv.version\n",
    "                )\n",
    "            else:\n",
    "                name, version = fv.split('/')\n",
    "                view = self.feature_store.get_feature_view(name, version)\n",
    "            views.append(view)\n",
    "        \n",
    "        if dataset_name is None:\n",
    "            # Use datetime.now() with timezone\n",
    "            timestamp = datetime.now(timezone.utc).strftime('%Y%m%d_%H%M%S')\n",
    "            unique_id = str(uuid.uuid4())[:8]\n",
    "            dataset_name = f\"DATASET_{timestamp}_{unique_id}\"\n",
    "        \n",
    "        dataset = self.feature_store.generate_dataset(\n",
    "            name=dataset_name,\n",
    "            spine_df=spine_df,\n",
    "            features=views,\n",
    "            spine_label_cols=label_cols,\n",
    "            spine_timestamp_col=spine_timestamp_col,\n",
    "            **kwargs\n",
    "        )\n",
    "        \n",
    "        return dataset.read.to_snowpark_dataframe()\n",
    "\n",
    "    \n",
    "    def _validate_sql(self, df: DataFrame) -> None:\n",
    "        \"\"\"Validate the SQL that will be generated\n",
    "        \n",
    "        Args:\n",
    "            df: DataFrame to validate\n",
    "            \n",
    "        Raises:\n",
    "            ValueError: If SQL validation fails\n",
    "        \"\"\"\n",
    "        try:\n",
    "            # Get the SQL query\n",
    "            sql = df.queries['queries'][0]\n",
    "            \n",
    "            # Try executing the query with LIMIT 0 to validate syntax\n",
    "            test_sql = f\"SELECT * FROM ({sql}) LIMIT 0\"\n",
    "            self.connection.session.sql(test_sql).collect()\n",
    "            \n",
    "        except Exception as e:\n",
    "            for cb in self.callbacks:\n",
    "                cb.on_error(f\"SQL validation failed: {str(e)}\")\n",
    "            raise ValueError(f\"SQL validation failed: {str(e)}\")\n",
    "        \n",
    "    def _validate_schema_only(self, df: DataFrame) -> None:\n",
    "        \"\"\"Validate DataFrame schema without triggering execution\"\"\"\n",
    "        try:\n",
    "            from snowflake.snowpark.types import (\n",
    "                StringType, IntegerType, FloatType, LongType, \n",
    "                DateType, TimestampType, DoubleType, BooleanType\n",
    "            )\n",
    "            \n",
    "            valid_types = {\n",
    "                type(StringType()): 'string',\n",
    "                type(IntegerType()): 'integer',\n",
    "                type(FloatType()): 'float',\n",
    "                type(LongType()): 'long',\n",
    "                type(DateType()): 'date',\n",
    "                type(TimestampType()): 'timestamp',\n",
    "                type(DoubleType()): 'double',\n",
    "                type(BooleanType()): 'boolean'\n",
    "            }\n",
    "            \n",
    "            schema = df.schema\n",
    "            if not schema:\n",
    "                raise ValueError(\"DataFrame has no schema\")\n",
    "                \n",
    "            for field in schema.fields:\n",
    "                field_type = type(field.datatype)\n",
    "                if field_type not in valid_types:\n",
    "                    raise ValueError(\n",
    "                        f\"Unsupported data type for field {field.name}: \"\n",
    "                        f\"{field.datatype} (type: {field_type})\"\n",
    "                    )\n",
    "                        \n",
    "        except Exception as e:\n",
    "            for cb in self.callbacks:\n",
    "                cb.on_error(f\"Schema validation failed: {str(e)}\")\n",
    "            raise ValueError(f\"Schema validation failed: {str(e)}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export \n",
    "\n",
    "@contextmanager\n",
    "def feature_store_session(connection: SnowflakeConnection, \n",
    "                         schema_name: Optional[str] = None,\n",
    "                         cleanup: bool = True):\n",
    "    \"\"\"Context manager for feature store operations\"\"\"\n",
    "    schema = schema_name or f\"FEATURE_STORE_{datetime.now(timezone.utc).strftime('%Y%m%d_%H%M%S')}_{uuid.uuid4().hex[:8]}\"\n",
    "    original_schema = connection.schema\n",
    "    \n",
    "    try:\n",
    "        # Create schema\n",
    "        connection.session.sql(f\"CREATE SCHEMA IF NOT EXISTS {connection.database}.{schema}\").collect()\n",
    "        \n",
    "        # Set the schema as current\n",
    "        connection.session.sql(f\"USE SCHEMA {connection.database}.{schema}\").collect()\n",
    "        connection.schema = schema\n",
    "        \n",
    "        # Create and yield manager\n",
    "        manager = FeatureStoreManager(\n",
    "            connection=connection,\n",
    "            callbacks=[PrintCallback()],\n",
    "            overwrite=True\n",
    "        )\n",
    "        yield manager\n",
    "        \n",
    "    finally:\n",
    "        if cleanup:\n",
    "            try:\n",
    "                # Cleanup schema and all objects\n",
    "                connection.session.sql(f\"DROP SCHEMA IF EXISTS {connection.database}.{schema} CASCADE\").collect()\n",
    "            except Exception as e:\n",
    "                print(f\"Cleanup failed: {str(e)}\")\n",
    "            \n",
    "            # Restore original schema\n",
    "            try:\n",
    "                connection.session.sql(f\"USE SCHEMA {connection.database}.{original_schema}\").collect()\n",
    "                connection.schema = original_schema\n",
    "            except Exception as e:\n",
    "                print(f\"Failed to restore original schema: {str(e)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | hide\n",
    "# Test setup\n",
    "from snowflake_feature_store.connection import get_connection\n",
    "from datetime import datetime, timezone \n",
    "\n",
    "def test_feature_store_manager():\n",
    "    \"Test feature store manager functionality\"\n",
    "    try:\n",
    "        conn = get_connection()\n",
    "        session = conn.session\n",
    "        test_schema = \"TEST_FEATURE_STORE\"\n",
    "        \n",
    "        # Create unique identifier for test run to avoid conflicts\n",
    "        test_id =  datetime.now(timezone.utc).strftime('%Y%m%d_%H%M%S')\n",
    "        test_table = f\"customer_test_data_{test_id}\"\n",
    "        \n",
    "        # Create test schema and table\n",
    "        try:\n",
    "            session.sql(f\"CREATE SCHEMA IF NOT EXISTS {test_schema}\").collect()\n",
    "            session.sql(f\"\"\"\n",
    "                CREATE OR REPLACE TABLE {test_schema}.{test_table} (\n",
    "                    CUSTOMER_ID STRING,\n",
    "                    SESSION_LENGTH INT,\n",
    "                    PURCHASES INT\n",
    "                )\n",
    "            \"\"\").collect()\n",
    "            \n",
    "            # Insert test data\n",
    "            session.sql(f\"\"\"\n",
    "                INSERT INTO {test_schema}.{test_table} VALUES\n",
    "                ('C1', 10, 100),\n",
    "                ('C2', 20, 200)\n",
    "            \"\"\").collect()\n",
    "            \n",
    "            # Create manager with overwrite=True to handle existing objects\n",
    "            manager = FeatureStoreManager(\n",
    "                conn, \n",
    "                callbacks=[PrintCallback()],\n",
    "                overwrite=True  # Add this to handle existing feature views\n",
    "            )\n",
    "            \n",
    "            # Test entity creation\n",
    "            manager.add_entity(\"TEST_CUSTOMER\", [\"CUSTOMER_ID\"])\n",
    "            assert \"TEST_CUSTOMER\" in manager.entities\n",
    "            \n",
    "            # Create DataFrame from permanent table\n",
    "            df = session.table(f\"{test_schema}.{test_table}\")\n",
    "            \n",
    "            # Create feature view with unique name\n",
    "            config = FeatureViewConfig(\n",
    "                name=f\"test_behavior_{test_id}\",  # Make name unique\n",
    "                domain=\"TEST\",\n",
    "                entity=\"TEST_CUSTOMER\",\n",
    "                feature_descriptions={\n",
    "                    \"SESSION_LENGTH\": \"Test session length\",\n",
    "                    \"PURCHASES\": \"Test purchases\"\n",
    "                }\n",
    "            )\n",
    "            \n",
    "            try:\n",
    "                feature_view = manager.add_feature_view(config, df, \"TEST_CUSTOMER\")\n",
    "                assert feature_view is not None\n",
    "                \n",
    "                # Test feature retrieval\n",
    "                spine_df = session.sql(f\"SELECT CUSTOMER_ID FROM {test_schema}.{test_table}\")\n",
    "                \n",
    "                features_df = manager.get_features(\n",
    "                    spine_df=spine_df,\n",
    "                    feature_views=[f\"{config.full_name}/{config.version}\"]\n",
    "                )\n",
    "                assert features_df is not None\n",
    "                assert features_df.count() == 2\n",
    "                \n",
    "            except Exception as e:\n",
    "                print(f\"Error in feature view creation/retrieval: {str(e)}\")\n",
    "                raise\n",
    "                \n",
    "        finally:\n",
    "            # Cleanup test objects\n",
    "            session.sql(f\"DROP SCHEMA IF EXISTS {test_schema} CASCADE\").collect()\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"Error in test setup: {str(e)}\")\n",
    "        raise\n",
    "\n",
    "\n",
    "# Run tests with error handling\n",
    "try:\n",
    "    test_feature_store_manager()\n",
    "except Exception as e:\n",
    "    print(f\"Test failed: {str(e)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "import nbdev; nbdev.nbdev_export()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "FeatureStore.get_entity() is in private preview since 1.0.8. Do not use it in production. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created entity: CUSTOMER with keys: ['CUSTOMER_ID']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jdemlow/miniconda3/envs/feature_store/lib/python3.9/site-packages/snowflake/ml/feature_store/feature_store.py:1067: UserWarning: Your pipeline won't be incrementally refreshed due to: \"Query contains the function 'CURRENT_DATE', but change tracking is not supported on queries with non-deterministic functions.\". It will likely incurr higher cost.\n",
      "  self._check_dynamic_table_refresh_mode(feature_view_name)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created feature view: FV_RETAIL_CUSTOMER_BEHAVIOR with 5 features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:A Column with DATE or TIMESTAMP data type detected. It might not be able to get converted to tensors. Please consider handle it in feature engineering.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Feature view created successfully:\n",
      "Name: FV_RETAIL_CUSTOMER_BEHAVIOR\n",
      "\n",
      "Retrieved features:\n",
      "---------------------------------------------------------------------------------------------------\n",
      "|\"CUSTOMER_ID\"  |\"TARGET\"  |\"SESSION_LENGTH\"  |\"PURCHASES\"  |\"SIGNUP_DATE\"  |\"DAYS_SINCE_SIGNUP\"  |\n",
      "---------------------------------------------------------------------------------------------------\n",
      "|C1             |100       |10                |100          |2024-01-01     |406                  |\n",
      "|C2             |200       |20                |200          |2024-01-02     |405                  |\n",
      "---------------------------------------------------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# | eval: false\n",
    "from snowflake_feature_store.manager import *\n",
    "from snowflake_feature_store.transforms import fill_na, date_diff\n",
    "from snowflake_feature_store.connection import get_connection\n",
    "\n",
    "conn = get_connection()\n",
    "session = conn.session\n",
    "\n",
    "# Use context manager for automatic cleanup\n",
    "with feature_store_session(conn) as manager:\n",
    "    current_schema = manager.connection.schema  # Get the current schema\n",
    "    \n",
    "    # Add entity\n",
    "    manager.add_entity(\n",
    "        name=\"CUSTOMER\",\n",
    "        join_keys=[\"CUSTOMER_ID\"],\n",
    "        description=\"Customer entity\"\n",
    "    )\n",
    "    \n",
    "    # Create source table with fully qualified name\n",
    "    manager.connection.session.sql(f\"\"\"\n",
    "        CREATE OR REPLACE TABLE {manager.connection.database}.{current_schema}.CUSTOMER_SOURCE (\n",
    "            CUSTOMER_ID STRING,\n",
    "            SESSION_LENGTH INT,\n",
    "            PURCHASES INT,\n",
    "            SIGNUP_DATE DATE\n",
    "        )\n",
    "    \"\"\").collect()\n",
    "    \n",
    "    # Insert test data using fully qualified name\n",
    "    manager.connection.session.sql(f\"\"\"\n",
    "        INSERT INTO {manager.connection.database}.{current_schema}.CUSTOMER_SOURCE VALUES\n",
    "        ('C1', 10, 100, '2024-01-01'),\n",
    "        ('C2', 20, 200, '2024-01-02')\n",
    "    \"\"\").collect()\n",
    "    \n",
    "    # Create DataFrame using fully qualified name\n",
    "    df = manager.connection.session.table(\n",
    "        f\"{manager.connection.database}.{current_schema}.CUSTOMER_SOURCE\"\n",
    "    )\n",
    "    \n",
    "    # Create feature view config\n",
    "    config = FeatureViewConfig(\n",
    "        name=\"customer_behavior\",\n",
    "        domain=\"RETAIL\",\n",
    "        feature_type=\"BEHAVIOR\",\n",
    "        feature_descriptions={\n",
    "            \"SESSION_LENGTH\": \"Session length in minutes\",\n",
    "            \"PURCHASES\": \"Number of purchases\",\n",
    "            \"DAYS_SINCE_SIGNUP\": \"Days since customer signup\"\n",
    "        }\n",
    "    )\n",
    "    \n",
    "    # Define transforms\n",
    "    transforms = [\n",
    "        fill_na(['SESSION_LENGTH']),\n",
    "        date_diff('SIGNUP_DATE', 'DAYS_SINCE_SIGNUP')\n",
    "    ]\n",
    "    \n",
    "    # Create feature view\n",
    "    feature_view = manager.add_feature_view(\n",
    "        config=config,\n",
    "        df=df,\n",
    "        entity_name=\"CUSTOMER\",\n",
    "        transforms=transforms\n",
    "    )\n",
    "    \n",
    "    # Create spine DataFrame for feature retrieval using fully qualified name\n",
    "    spine_df = manager.connection.session.sql(f\"\"\"\n",
    "        SELECT CUSTOMER_ID, PURCHASES as target \n",
    "        FROM {manager.connection.database}.{current_schema}.CUSTOMER_SOURCE\n",
    "    \"\"\")\n",
    "    \n",
    "    # Get features for training\n",
    "    features_df = manager.get_features(\n",
    "        spine_df=spine_df,\n",
    "        feature_views=[config],\n",
    "        label_cols=['target'],\n",
    "        dataset_name=\"TRAINING_DATA\"\n",
    "    )\n",
    "    \n",
    "    # Show results\n",
    "    print(\"\\nFeature view created successfully:\")\n",
    "    print(f\"Name: {feature_view.name}\")\n",
    "    print(\"\\nRetrieved features:\")\n",
    "    features_df.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "feature_store",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
