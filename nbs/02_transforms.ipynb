{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NAME\n",
    "\n",
    "> Fill in a module description here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "from __future__ import annotations\n",
    "from typing import Union, List, Callable, Optional, Protocol, Dict\n",
    "from dataclasses import dataclass\n",
    "from fastcore.basics import listify\n",
    "import snowflake.snowpark.functions as F\n",
    "from snowflake.snowpark import DataFrame, Window"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class Transform(Protocol):\n",
    "    \"Protocol for feature transformations\"\n",
    "    def __call__(self, df: DataFrame) -> DataFrame: ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "\n",
    "from snowflake_feature_store.connection import get_connection, ConnectionConfig\n",
    "\n",
    "# Method 1: Get connection automatically\n",
    "conn = get_connection()\n",
    "session = conn.session\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "@dataclass\n",
    "class WindowSpec:\n",
    "    \"Configuration for window-based transformations\"\n",
    "    partition_by: Optional[Union[str, List[str]]] = None\n",
    "    order_by: Optional[Union[str, List[str]]] = None\n",
    "    window_size: Optional[int] = None\n",
    "    \n",
    "    def __post_init__(self):\n",
    "        \"Convert string inputs to lists\"\n",
    "        if isinstance(self.partition_by, str):\n",
    "            self.partition_by = [self.partition_by]\n",
    "        if isinstance(self.order_by, str):\n",
    "            self.order_by = [self.order_by]\n",
    "            \n",
    "    def to_window(self) -> Window:\n",
    "        \"Convert to Snowpark Window specification\"\n",
    "        window = Window.partition_by(self.partition_by or []) \\\n",
    "                      .order_by(self.order_by or [])\n",
    "        \n",
    "        if self.window_size:\n",
    "            window = window.rows_between(\n",
    "                -(self.window_size-1),\n",
    "                Window.CURRENT_ROW\n",
    "            )\n",
    "        return window\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def window_agg(\n",
    "    agg_cols: Dict[str, List[str]],\n",
    "    window_spec: WindowSpec\n",
    ") -> Transform:\n",
    "    \"\"\"Apply window-based aggregations\n",
    "    \n",
    "    Args:\n",
    "        agg_cols: Dictionary mapping columns to aggregation functions\n",
    "        window_spec: Window specification for the aggregation\n",
    "        \n",
    "    Returns:\n",
    "        Transform function\n",
    "        \n",
    "    Example:\n",
    "        >>> spec = WindowSpec(partition_by='customer_id', order_by='date')\n",
    "        >>> aggs = {'amount': ['SUM', 'AVG']}\n",
    "        >>> window_agg(aggs, spec)(df)\n",
    "    \"\"\"\n",
    "    def _inner(df: DataFrame) -> DataFrame:\n",
    "        # Use the WindowSpec's to_window method\n",
    "        window = window_spec.to_window()\n",
    "            \n",
    "        for col, aggs in agg_cols.items():\n",
    "            for agg in aggs:\n",
    "                agg_func = getattr(F, agg.lower())\n",
    "                # Snowflake typically uppercases column names\n",
    "                new_col = f\"{agg.upper()}_{col.upper()}\"\n",
    "                df = df.with_column(\n",
    "                    new_col,\n",
    "                    agg_func(F.col(col)).over(window)\n",
    "                )\n",
    "        return df\n",
    "    return _inner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Result with window aggregations:\n",
      "-----------------------------------------------------------------------\n",
      "|\"CUSTOMER_ID\"  |\"DATE\"      |\"AMOUNT\"  |\"SUM_AMOUNT\"  |\"AVG_AMOUNT\"  |\n",
      "-----------------------------------------------------------------------\n",
      "|C2             |2024-01-01  |150       |150           |150.000       |\n",
      "|C1             |2024-01-01  |100       |100           |100.000       |\n",
      "|C1             |2024-01-02  |200       |300           |150.000       |\n",
      "-----------------------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#| hide\n",
    "def test_window_agg():\n",
    "    \"Test window-based aggregations with fixed implementation\"\n",
    "    # Create test dataframe\n",
    "    data = [\n",
    "        ['C1', '2024-01-01', 100],\n",
    "        ['C1', '2024-01-02', 200],\n",
    "        ['C2', '2024-01-01', 150]\n",
    "    ]\n",
    "    df = session.create_dataframe(data, ['customer_id', 'date', 'amount'])\n",
    "    \n",
    "    # Test with window size\n",
    "    spec = WindowSpec(\n",
    "        partition_by='customer_id',\n",
    "        order_by='date',\n",
    "        window_size=2\n",
    "    )\n",
    "    \n",
    "    result = window_agg(\n",
    "        {'amount': ['SUM', 'AVG']},\n",
    "        spec\n",
    "    )(df)\n",
    "    \n",
    "    # Show results for debugging\n",
    "    print(\"\\nResult with window aggregations:\")\n",
    "    result.show()\n",
    "    \n",
    "    # Create a dictionary for easy lookup by customer_id and date\n",
    "    results_dict = {\n",
    "        (row['CUSTOMER_ID'], row['DATE']): row \n",
    "        for row in result.collect()\n",
    "    }\n",
    "    \n",
    "    # Test C1 customer values\n",
    "    c1_jan1 = results_dict[('C1', '2024-01-01')]\n",
    "    c1_jan2 = results_dict[('C1', '2024-01-02')]\n",
    "    assert c1_jan1['SUM_AMOUNT'] == 100, \"C1's first day should sum to 100\"\n",
    "    assert c1_jan2['SUM_AMOUNT'] == 300, \"C1's second day should sum to 300\"\n",
    "    \n",
    "    # Test C2 customer values\n",
    "    c2_jan1 = results_dict[('C2', '2024-01-01')]\n",
    "    assert c2_jan1['SUM_AMOUNT'] == 150, \"C2's only day should sum to 150\"\n",
    "    \n",
    "    # Test averages\n",
    "    assert c1_jan1['AVG_AMOUNT'] == 100, \"C1's first day average should be 100\"\n",
    "    assert c1_jan2['AVG_AMOUNT'] == 150, \"C1's second day average should be 150\"\n",
    "    assert c2_jan1['AVG_AMOUNT'] == 150, \"C2's average should be 150\"\n",
    "\n",
    "test_window_agg()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "def fill_na(cols: Union[str, List[str]], fill_value: Union[int, float, str] = 0) -> Transform:\n",
    "    \"\"\"Fill NA values in specified columns, matching the column type\n",
    "    \n",
    "    Args:\n",
    "        cols: Column(s) to fill NA values in\n",
    "        fill_value: Value to use for filling NAs (will be cast to match column type)\n",
    "        \n",
    "    Returns:\n",
    "        Transform function\n",
    "        \n",
    "    Example:\n",
    "        >>> df = session.create_dataframe([[1, None], [2, 3]], ['A', 'B'])\n",
    "        >>> fill_na('B', 0)(df).collect()\n",
    "        [[1, 0], [2, 3]]\n",
    "    \"\"\"\n",
    "    cols = listify(cols)\n",
    "    def _inner(df: DataFrame) -> DataFrame:\n",
    "        for col in cols:\n",
    "            # Find actual column name (case-insensitive)\n",
    "            actual_col = next(\n",
    "                (c for c in df.schema.names if c.upper() == col.upper()),\n",
    "                None\n",
    "            )\n",
    "            if actual_col is None:\n",
    "                raise ValueError(f\"Column {col} not found in DataFrame\")\n",
    "            \n",
    "            # Get column type\n",
    "            col_type = df.schema[actual_col].datatype\n",
    "            \n",
    "            # Cast fill value to match column type\n",
    "            typed_value = (\n",
    "                int(fill_value) if str(col_type).startswith(('Long', 'Int')) \n",
    "                else float(fill_value) if str(col_type).startswith('Double') \n",
    "                else str(fill_value)\n",
    "            )\n",
    "            \n",
    "            df = df.na.fill({actual_col: typed_value})\n",
    "        return df\n",
    "    return _inner\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "def test_fill_na():\n",
    "    \"Test fill_na works with different case column names\"\n",
    "    from snowflake.snowpark.types import StructType, StructField, LongType\n",
    "    \n",
    "    schema = StructType([\n",
    "        StructField(\"COLUMN_A\", LongType()),\n",
    "        StructField(\"COLUMN_B\", LongType())\n",
    "    ])\n",
    "    data = [[1, None], [2, 3]]\n",
    "    df = session.create_dataframe(data, schema)\n",
    "    \n",
    "    # Test with different cases\n",
    "    result1 = fill_na('COLUMN_B', 0)(df).collect()\n",
    "    result2 = fill_na('column_b', 0)(df).collect()\n",
    "    \n",
    "    assert result1[0].COLUMN_B == 0\n",
    "    assert result2[0].COLUMN_B == 0\n",
    "\n",
    "# Run all tests\n",
    "test_fill_na()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#| export\n",
    "\n",
    "def date_diff(\n",
    "    col: str,\n",
    "    new_col: str,\n",
    "    reference_date: Optional[str] = None,\n",
    "    date_part: str = 'day'\n",
    ") -> Transform:\n",
    "    \"\"\"Calculate date difference between column and reference\n",
    "    \n",
    "    Args:\n",
    "        col: Date column to calculate difference from\n",
    "        new_col: Name for the new difference column\n",
    "        reference_date: Reference date (default: current_date)\n",
    "        date_part: Part to calculate difference in ('day', 'month', etc.)\n",
    "        \n",
    "    Returns:\n",
    "        Transform function\n",
    "        \n",
    "    Example:\n",
    "        >>> df = session.create_dataframe([['2024-01-01']], ['date'])\n",
    "        >>> date_diff('date', 'days_ago', '2024-02-01')(df).collect()\n",
    "        [['2024-01-01', 31]]\n",
    "    \"\"\"\n",
    "    def _inner(df: DataFrame) -> DataFrame:\n",
    "        # Ensure column exists (case-insensitive)\n",
    "        col_actual = [c for c in df.columns if c.upper() == col.upper()][0]\n",
    "        \n",
    "        reference = (F.to_date(F.lit(reference_date)) \n",
    "                    if isinstance(reference_date, str)\n",
    "                    else F.current_date())\n",
    "        \n",
    "        return df.with_column(\n",
    "            new_col.upper(),  # Standardize output column name\n",
    "            F.datediff(date_part, F.col(col_actual), reference)\n",
    "        )\n",
    "    return _inner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transformed DataFrame Schema:\n",
      "StructType([StructField('DATE', DateType(), nullable=True), StructField('DAYS_AGO', LongType(), nullable=True)])\n",
      "\n",
      "Transformed DataFrame Data:\n",
      "---------------------------\n",
      "|\"DATE\"      |\"DAYS_AGO\"  |\n",
      "---------------------------\n",
      "|2024-01-01  |60          |\n",
      "|2024-02-01  |29          |\n",
      "---------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#| hide\n",
    "def test_date_diff():\n",
    "    \"Test date difference calculation\"\n",
    "    # Create test dataframe with proper schema\n",
    "    from snowflake.snowpark.types import StructType, StructField, DateType\n",
    "    \n",
    "    schema = StructType([StructField(\"DATE\", DateType())])\n",
    "    data = [['2024-01-01'], ['2024-02-01']]\n",
    "    df = session.create_dataframe(data, schema)\n",
    "    \n",
    "    # Apply transformation\n",
    "    transformed_df = date_diff('DATE', 'DAYS_AGO', '2024-03-01')(df)\n",
    "    \n",
    "    # Show the result for debugging\n",
    "    print(\"Transformed DataFrame Schema:\")\n",
    "    print(transformed_df.schema)\n",
    "    print(\"\\nTransformed DataFrame Data:\")\n",
    "    transformed_df.show()\n",
    "    \n",
    "    # Collect results and verify\n",
    "    result = transformed_df.collect()\n",
    "    \n",
    "    # Access columns case-insensitively\n",
    "    days_ago_col = [col for col in result[0].asDict().keys() if col.upper() == 'DAYS_AGO'][0]\n",
    "    \n",
    "    # Verify results\n",
    "    assert result[0][days_ago_col] == 60\n",
    "    assert result[1][days_ago_col] == 29\n",
    "\n",
    "# Run the test\n",
    "test_date_diff()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def moving_agg(\n",
    "    cols: Union[str, List[str]],\n",
    "    window_sizes: List[int],\n",
    "    agg_funcs: List[str] = ['SUM', 'AVG'],\n",
    "    partition_by: Optional[List[str]] = None,\n",
    "    order_by: Optional[List[str]] = None\n",
    ") -> Transform:\n",
    "    \"\"\"Calculate moving window aggregations\n",
    "    \n",
    "    Args:\n",
    "        cols: Columns to aggregate\n",
    "        window_sizes: List of window sizes\n",
    "        agg_funcs: List of aggregation functions\n",
    "        partition_by: Columns to partition by\n",
    "        order_by: Columns to order by\n",
    "        \n",
    "    Returns:\n",
    "        Transform function\n",
    "        \n",
    "    Example:\n",
    "        >>> moving_agg('amount', [3, 7], ['SUM'], ['customer_id'], ['date'])(df)\n",
    "    \"\"\"\n",
    "    cols = listify(cols)\n",
    "    def _inner(df: DataFrame) -> DataFrame:\n",
    "        for col in cols:\n",
    "            for size in window_sizes:\n",
    "                spec = WindowSpec(\n",
    "                    partition_by=partition_by,\n",
    "                    order_by=order_by,\n",
    "                    window_size=size\n",
    "                )\n",
    "                aggs = {col: agg_funcs}\n",
    "                df = window_agg(aggs, spec)(df)\n",
    "        return df\n",
    "    return _inner\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def cumulative_agg(\n",
    "    cols: Union[str, List[str]],\n",
    "    agg_funcs: List[str] = ['SUM'],\n",
    "    partition_by: Optional[List[str]] = None,\n",
    "    order_by: Optional[List[str]] = None\n",
    ") -> Transform:\n",
    "    \"\"\"Calculate cumulative aggregations\n",
    "    \n",
    "    Args:\n",
    "        cols: Columns to aggregate\n",
    "        agg_funcs: List of aggregation functions\n",
    "        partition_by: Columns to partition by\n",
    "        order_by: Columns to order by\n",
    "        \n",
    "    Returns:\n",
    "        Transform function\n",
    "        \n",
    "    Example:\n",
    "        >>> cumulative_agg('amount', ['SUM'], ['customer_id'], ['date'])(df)\n",
    "    \"\"\"\n",
    "    return moving_agg(\n",
    "        cols=cols,\n",
    "        window_sizes=[None],  # None means unbounded\n",
    "        agg_funcs=agg_funcs,\n",
    "        partition_by=partition_by,\n",
    "        order_by=order_by\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def apply_transforms(df: DataFrame, transforms: List[Transform]) -> DataFrame:\n",
    "    \"\"\"Apply a list of transformations to a DataFrame\n",
    "    \n",
    "    Args:\n",
    "        df: Input DataFrame\n",
    "        transforms: List of transform functions to apply\n",
    "        \n",
    "    Returns:\n",
    "        Transformed DataFrame\n",
    "        \n",
    "    Example:\n",
    "        >>> transforms = [\n",
    "        ...     fill_na(['score']),\n",
    "        ...     date_diff('date', 'days_ago')\n",
    "        ... ]\n",
    "        >>> apply_transforms(df, transforms)\n",
    "    \"\"\"\n",
    "    for transform in transforms:\n",
    "        df = transform(df)\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "def test_apply_transforms():\n",
    "    \"Test applying multiple transforms\"\n",
    "    # Create test data\n",
    "    data = [\n",
    "        ['C1', '2024-01-01', 100, None],\n",
    "        ['C1', '2024-01-02', 200, 3.5]\n",
    "    ]\n",
    "    df = session.create_dataframe(data, ['customer_id', 'date', 'amount', 'score'])\n",
    "    \n",
    "    # Define transforms\n",
    "    transforms = [\n",
    "        fill_na(['score']),\n",
    "        date_diff('date', 'days_ago', '2024-02-01')\n",
    "    ]\n",
    "    \n",
    "    # Apply transforms\n",
    "    result = apply_transforms(df, transforms)\n",
    "    \n",
    "    # Verify results\n",
    "    collected = result.collect()\n",
    "    assert collected[0]['SCORE'] == 0  # NA was filled\n",
    "    assert collected[0]['DAYS_AGO'] == 31  # Date diff was calculated\n",
    "\n",
    "test_apply_transforms()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "import nbdev; nbdev.nbdev_export()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Transformed DataFrame:\n",
      "----------------------------------------------------------------------------------------------\n",
      "|\"CUSTOMER_ID\"  |\"DATE\"      |\"AMOUNT\"  |\"SCORE\"  |\"DAYS_AGO\"  |\"AVG_AMOUNT\"  |\"SUM_AMOUNT\"  |\n",
      "----------------------------------------------------------------------------------------------\n",
      "|C1             |2024-01-01  |100       |0.0      |31          |100.000       |100           |\n",
      "|C1             |2024-01-02  |200       |3.5      |30          |150.000       |300           |\n",
      "|C2             |2024-01-01  |150       |0.0      |31          |150.000       |150           |\n",
      "----------------------------------------------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#| eval: false\n",
    "# Example usage\n",
    "from snowflake_feature_store.transforms import *\n",
    "\n",
    "# Example usage with apply_transforms\n",
    "df = session.create_dataframe([\n",
    "    ['C1', '2024-01-01', 100, None],\n",
    "    ['C1', '2024-01-02', 200, 3.5],\n",
    "    ['C2', '2024-01-01', 150, None]\n",
    "], ['customer_id', 'date', 'amount', 'score'])\n",
    "\n",
    "df_transformed = apply_transforms(df, [\n",
    "    fill_na(['score']),\n",
    "    date_diff('date', 'days_ago', '2024-02-01'),\n",
    "    moving_agg(\n",
    "        'amount',\n",
    "        window_sizes=[3],  # Simplified for testing\n",
    "        partition_by=['customer_id'],\n",
    "        order_by=['date']\n",
    "    ),\n",
    "    cumulative_agg(\n",
    "        'amount',\n",
    "        partition_by=['customer_id'],\n",
    "        order_by=['date']\n",
    "    )\n",
    "])\n",
    "\n",
    "print(\"\\nTransformed DataFrame:\")\n",
    "df_transformed.show()\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "feature_store",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
