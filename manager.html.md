# Manager (Features)


<!-- WARNING: THIS FILE WAS AUTOGENERATED! DO NOT EDIT! -->

------------------------------------------------------------------------

<a
href="https://github.com/Jeremy-Demlow/sf-feature-store/blob/main/snowflake_feature_store/manager.py#L47"
target="_blank" style="float:right; font-size:smaller">source</a>

### FeatureStoreCallback

>  FeatureStoreCallback ()

*Protocol for feature store callbacks*

------------------------------------------------------------------------

<a
href="https://github.com/Jeremy-Demlow/sf-feature-store/blob/main/snowflake_feature_store/manager.py#L60"
target="_blank" style="float:right; font-size:smaller">source</a>

### MetricsCallback

>  MetricsCallback (metrics_path:Optional[pathlib.Path]=None)

*Callback that logs metrics and statistics*

------------------------------------------------------------------------

<a
href="https://github.com/Jeremy-Demlow/sf-feature-store/blob/main/snowflake_feature_store/manager.py#L119"
target="_blank" style="float:right; font-size:smaller">source</a>

### FeatureStoreManager

>  FeatureStoreManager
>                           (connection:snowflake_feature_store.connection.Snowf
>                           lakeConnection, callbacks:Optional[List[__main__.Fea
>                           tureStoreCallback]]=None,
>                           metrics_path:Union[str,pathlib.Path,NoneType]=None,
>                           overwrite:bool=False)

*Manages feature store operations with monitoring and dependency
tracking*

------------------------------------------------------------------------

<a
href="https://github.com/Jeremy-Demlow/sf-feature-store/blob/main/snowflake_feature_store/manager.py#L498"
target="_blank" style="float:right; font-size:smaller">source</a>

### feature_store_session

>  feature_store_session
>                             (connection:snowflake_feature_store.connection.Sno
>                             wflakeConnection, schema_name:Optional[str]=None, 
>                             metrics_path:Union[str,pathlib.Path,NoneType]=None
>                             , cleanup:bool=True)

\*Context manager for feature store operations

Args: connection: Snowflake connection schema_name: Optional schema name
(keyword only) metrics_path: Optional path to save metrics (keyword
only) cleanup: Whether to cleanup schema after use (keyword only)\*

<table>
<thead>
<tr>
<th></th>
<th><strong>Type</strong></th>
<th><strong>Default</strong></th>
<th><strong>Details</strong></th>
</tr>
</thead>
<tbody>
<tr>
<td>connection</td>
<td>SnowflakeConnection</td>
<td></td>
<td></td>
</tr>
<tr>
<td>schema_name</td>
<td>Optional</td>
<td>None</td>
<td>Force keyword arguments</td>
</tr>
<tr>
<td>metrics_path</td>
<td>Union</td>
<td>None</td>
<td>Changed type hint</td>
</tr>
<tr>
<td>cleanup</td>
<td>bool</td>
<td>True</td>
<td></td>
</tr>
</tbody>
</table>

``` python
from snowflake_feature_store.connection import get_connection
from snowflake_feature_store.config import (
    FeatureViewConfig, FeatureConfig, FeatureValidationConfig, RefreshConfig
)
from snowflake_feature_store.transforms import TransformConfig, moving_agg, fill_na
from snowflake_feature_store.manager import feature_store_session
import snowflake.snowpark.functions as F
from datetime import datetime
import tempfile
from pathlib import Path

# Create a temporary directory for metrics
metrics_dir = Path(tempfile.mkdtemp()) / "feature_store_metrics"

# Get connection
conn = get_connection()

# Use the feature store session context manager
with feature_store_session(conn, metrics_path=str(metrics_dir)) as manager:
    # Create sample data
    # First, create a regular table to store our data
    conn.session.sql("""
        CREATE OR REPLACE TABLE TEMP_CUSTOMER_DATA (
            CUSTOMER_ID STRING,
            DATE DATE,
            AMOUNT FLOAT,
            TRANSACTIONS INT,
            SESSION_LENGTH FLOAT
        )
    """).collect()
    
    # Insert the data using SQL
    conn.session.sql("""
        INSERT INTO TEMP_CUSTOMER_DATA VALUES
        ('C1', '2024-01-01', 100.0, 2, NULL),
        ('C1', '2024-01-02', 150.0, 3, 30.5),
        ('C2', '2024-01-01', 75.0, 1, NULL),
        ('C2', '2024-01-02', 200.0, 4, 45.2)
    """).collect()
    
    # Create feature DataFrame from the table
    df = conn.session.table("TEMP_CUSTOMER_DATA")
    
    print("\nInitial DataFrame Schema:")
    for field in df.schema.fields:
        print(f"{field.name}: {field.datatype}")
    
    print("\nSample Data:")
    df.show()
    
    # 1. Add Customer Entity
    manager.add_entity(
        name="CUSTOMER",
        join_keys=["CUSTOMER_ID"],
        description="Customer entity for retail domain"
    )
    
    # 2. Create Feature Configurations with dependencies
    feature_configs = {
        "AMOUNT": FeatureConfig(
            name="AMOUNT",
            description="Transaction amount",
            validation=FeatureValidationConfig(
                null_threshold=0.1,
                range_check=True,
                min_value=0
            ),
            dependencies=[]  # Base feature, no dependencies
        ),
        "TRANSACTIONS": FeatureConfig(
            name="TRANSACTIONS",
            description="Number of transactions",
            validation=FeatureValidationConfig(
                null_threshold=0.05,
                range_check=True,
                min_value=0
            ),
            dependencies=[]  # Base feature, no dependencies
        ),
        "SESSION_LENGTH": FeatureConfig(
            name="SESSION_LENGTH",
            description="Session length in minutes",
            validation=FeatureValidationConfig(
                null_threshold=0.3,
                range_check=True,
                min_value=0
            ),
            dependencies=[]  # Base feature, no dependencies
        ),
        "SUM_AMOUNT_2": FeatureConfig(
            name="SUM_AMOUNT_2",
            description="2-day rolling sum of amount",
            validation=FeatureValidationConfig(
                null_threshold=0.05,
                range_check=True,
                min_value=0
            ),
            dependencies=["AMOUNT"]  # Depends on AMOUNT
        ),
        "AVG_AMOUNT_2": FeatureConfig(
            name="AVG_AMOUNT_2",
            description="2-day rolling average of amount",
            validation=FeatureValidationConfig(
                null_threshold=0.05,
                range_check=True,
                min_value=0
            ),
            dependencies=["AMOUNT"]  # Depends on AMOUNT
        )
    }

    
    # 3. Create Feature View Config
    config = FeatureViewConfig(
        name="customer_behavior",
        domain="RETAIL",
        entity="CUSTOMER",
        feature_type="BEHAVIOR",
        refresh=RefreshConfig(frequency="1 day"),
        features=feature_configs,
        description="Customer behavior features",
        timestamp_col="DATE"
    )
    
    # 4. Create transforms
    transform_config = TransformConfig(
        name="amount_metrics",
        null_threshold=0.05,
        expected_types=['DECIMAL', 'DOUBLE', 'NUMBER']
    )
    
    transforms = [
        # Fill NA values in session length
        fill_na(['SESSION_LENGTH'], fill_value=0),
        
        # Calculate moving aggregations for amount
        moving_agg(
            cols='AMOUNT',
            window_sizes=[2],  # 2-day window
            agg_funcs=['SUM', 'AVG'],
            partition_by=['CUSTOMER_ID'],
            order_by=['DATE'],
            config=transform_config
        )
    ]
    
    # 5. Create Feature View
    feature_view = manager.add_feature_view(
        config=config,
        df=df,
        entity_name="CUSTOMER",
        transforms=transforms,
        collect_stats=True
    )
    
    # 6. Check for feature drift with new data
    # Create new table for drift detection
    conn.session.sql("""
        CREATE OR REPLACE TABLE TEMP_NEW_DATA (
            CUSTOMER_ID STRING,
            DATE DATE,
            AMOUNT FLOAT,
            TRANSACTIONS INT,
            SESSION_LENGTH FLOAT
        )
    """).collect()
    
    conn.session.sql("""
        INSERT INTO TEMP_NEW_DATA VALUES
        ('C1', '2024-01-03', 300.0, 5, 60.0),
        ('C2', '2024-01-03', 80.0, 1, 15.5)
    """).collect()
    
    new_df = conn.session.table("TEMP_NEW_DATA")
    
    drift_results = manager.check_feature_drift(config.name, new_df)
    print("\nDrift Detection Results:")
    for feature, metrics in drift_results.items():
        print(f"\n{feature}:")
        for metric, value in metrics.items():
            print(f"  {metric}: {value:.3f}")
    
    # 7. Get Feature Dependencies
    deps = manager.get_feature_dependencies(config.name)
    print("\nFeature Dependencies:", deps)
    
    # 8. Generate Training Dataset
    print("\nEntity join keys:")
    for entity in feature_view.entities:
        print(f"Entity {entity.name}: {entity.join_keys}")

    # Create spine DataFrame with explicit quoting
    spine_df = df.select([
        F.col('CUSTOMER_ID').alias('"CUSTOMER_ID"'),
        F.col('DATE').alias('"DATE"')
    ])

    print("\nSpine DataFrame columns:")
    print(spine_df.columns)
    print("\nSpine DataFrame schema:")
    for field in spine_df.schema.fields:
        print(f"{field.name}: {field.datatype}")

    training_data = manager.get_features(
        spine_df=spine_df,
        feature_views=[config],
        label_cols=["TRANSACTIONS"],
        spine_timestamp_col="DATE"
    )
    print("\nTraining Data Sample:")
    training_data.show(2)

    # After creating the feature view:
    print("\nFeature Statistics:")
    for feature_name, stats in manager.feature_stats[config.name].items():
        print(f"\n{feature_name}:")
        print(stats)
    
    print("\nTraining Data Schema:")
    for field in training_data.schema.fields:
        print(f"{field.name}: {field.datatype}")
    
    # Cleanup temporary tables
    conn.session.sql("DROP TABLE IF EXISTS TEMP_CUSTOMER_DATA").collect()
    conn.session.sql("DROP TABLE IF EXISTS TEMP_NEW_DATA").collect()
```

    2025-02-17 21:05:11,278 - snowflake_feature_store - INFO - Using active Snowflake session
    2025-02-17 21:05:11,279 - snowflake_feature_store - INFO - Initialized connection to "DATASCIENCE"."FEATURE_STORE_DEMO"
    2025-02-17 21:05:14,673 - snowflake_feature_store - INFO - FeatureStoreManager initialized

    Initial DataFrame Schema:
    CUSTOMER_ID: StringType()
    DATE: DateType()
    AMOUNT: DoubleType()
    TRANSACTIONS: LongType()
    SESSION_LENGTH: DoubleType()

    Sample Data:
    -----------------------------------------------------------------------------
    |"CUSTOMER_ID"  |"DATE"      |"AMOUNT"  |"TRANSACTIONS"  |"SESSION_LENGTH"  |
    -----------------------------------------------------------------------------
    |C1             |2024-01-01  |100.0     |2               |NULL              |
    |C1             |2024-01-02  |150.0     |3               |30.5              |
    |C2             |2024-01-01  |75.0      |1               |NULL              |
    |C2             |2024-01-02  |200.0     |4               |45.2              |
    -----------------------------------------------------------------------------

    2025-02-17 21:05:18,241 - snowflake_feature_store - INFO - Created entity: CUSTOMER with keys: ['CUSTOMER_ID']
    2025-02-17 21:05:22,346 - snowflake_feature_store - INFO - Validated feature AMOUNT (stats: {'timestamp': '2025-02-18T05:05:21.322713', 'row_count': 4, 'null_count': 0, 'null_ratio': 0.0, 'unique_count': 4, 'min_value': 75.0, 'max_value': 200.0, 'mean_value': 131.25, 'std_value': 55.433894565208625})
    2025-02-17 21:05:23,939 - snowflake_feature_store - INFO - Validated feature TRANSACTIONS (stats: {'timestamp': '2025-02-18T05:05:22.847648', 'row_count': 4, 'null_count': 0, 'null_ratio': 0.0, 'unique_count': 4, 'min_value': 1.0, 'max_value': 4.0, 'mean_value': 2.5, 'std_value': 1.290994577835244})
    2025-02-17 21:05:25,600 - snowflake_feature_store - INFO - Validated feature SESSION_LENGTH (stats: {'timestamp': '2025-02-18T05:05:24.371173', 'row_count': 4, 'null_count': 0, 'null_ratio': 0.0, 'unique_count': 3, 'min_value': 0.0, 'max_value': 45.2, 'mean_value': 18.925, 'std_value': 22.661770304487096})
    2025-02-17 21:05:27,676 - snowflake_feature_store - INFO - Validated feature SUM_AMOUNT_2 (stats: {'timestamp': '2025-02-18T05:05:26.006356', 'row_count': 4, 'null_count': 0, 'null_ratio': 0.0, 'unique_count': 4, 'min_value': 75.0, 'max_value': 275.0, 'mean_value': 175.0, 'std_value': 102.06207261596575})
    2025-02-17 21:05:29,551 - snowflake_feature_store - INFO - Validated feature AVG_AMOUNT_2 (stats: {'timestamp': '2025-02-18T05:05:28.391694', 'row_count': 4, 'null_count': 0, 'null_ratio': 0.0, 'unique_count': 4, 'min_value': 75.0, 'max_value': 137.5, 'mean_value': 109.375, 'std_value': 27.716947282604313})
    2025-02-17 21:05:42,824 - snowflake_feature_store - INFO - Created feature view: customer_behavior with 7 features
    2025-02-17 21:05:43,755 - snowflake_feature_store - INFO - Applying 2 transforms to new data
    2025-02-17 21:05:47,739 - snowflake_feature_store - WARNING - Drift detected in customer_behavior.AMOUNT: {'null_ratio_change': 0.0, 'mean_shift': 58.75, 'std_ratio': 2.806288338230435}
    2025-02-17 21:05:49,132 - snowflake_feature_store - WARNING - Drift detected in customer_behavior.TRANSACTIONS: {'null_ratio_change': 0.0, 'mean_shift': 0.5, 'std_ratio': 2.1908900109316742}
    2025-02-17 21:05:50,541 - snowflake_feature_store - WARNING - Drift detected in customer_behavior.SESSION_LENGTH: {'null_ratio_change': 0.0, 'mean_shift': 18.825, 'std_ratio': 1.3885169313789645}
    2025-02-17 21:05:52,132 - snowflake_feature_store - WARNING - Drift detected in customer_behavior.SUM_AMOUNT_2: {'null_ratio_change': 0.0, 'mean_shift': 15.0, 'std_ratio': 1.5242047106606122}
    2025-02-17 21:05:53,858 - snowflake_feature_store - WARNING - Drift detected in customer_behavior.AVG_AMOUNT_2: {'null_ratio_change': 0.0, 'mean_shift': 80.625, 'std_ratio': 5.61257667646087}

    Drift Detection Results:

    AMOUNT:
      null_ratio_change: 0.000
      mean_shift: 58.750
      std_ratio: 2.806

    TRANSACTIONS:
      null_ratio_change: 0.000
      mean_shift: 0.500
      std_ratio: 2.191

    SESSION_LENGTH:
      null_ratio_change: 0.000
      mean_shift: 18.825
      std_ratio: 1.389

    SUM_AMOUNT_2:
      null_ratio_change: 0.000
      mean_shift: 15.000
      std_ratio: 1.524

    AVG_AMOUNT_2:
      null_ratio_change: 0.000
      mean_shift: 80.625
      std_ratio: 5.613
    2025-02-17 21:05:53,861 - snowflake_feature_store - INFO - Dependencies for customer_behavior: {'customer_behavior'}

    Feature Dependencies: {'customer_behavior'}

    Entity join keys:
    Entity CUSTOMER: ['CUSTOMER_ID']

    Spine DataFrame columns:
    ['CUSTOMER_ID', 'DATE']

    Spine DataFrame schema:
    CUSTOMER_ID: StringType()
    DATE: DateType()
    2025-02-17 21:05:54,051 - snowflake_feature_store - INFO - Spine DataFrame columns: ['CUSTOMER_ID', 'DATE']
    2025-02-17 21:05:54,052 - snowflake_feature_store - INFO - Spine DataFrame schema: StructType([StructField('CUSTOMER_ID', StringType(), nullable=True), StructField('DATE', DateType(), nullable=True)])
    2025-02-17 21:05:56,507 - snowflake_feature_store - INFO - Generating dataset with name: DATASET_20250218_050556_eea51bbf
    2025-02-17 21:05:56,508 - snowflake_feature_store - INFO - Label columns: ['"TRANSACTIONS"']
    2025-02-17 21:05:56,509 - snowflake_feature_store - INFO - Timestamp column: "DATE"

    Training Data Sample:
    ----------------------------------------------------------------------------------------------------------------
    |"CUSTOMER_ID"  |"DATE"      |"AMOUNT"  |"TRANSACTIONS"  |"SESSION_LENGTH"   |"SUM_AMOUNT_2"  |"AVG_AMOUNT_2"  |
    ----------------------------------------------------------------------------------------------------------------
    |C2             |2024-01-01  |75.0      |1               |0.0                |75.0            |75.0            |
    |C2             |2024-01-02  |200.0     |4               |45.20000076293945  |275.0           |137.5           |
    ----------------------------------------------------------------------------------------------------------------


    Feature Statistics:

    AMOUNT:
    Timestamp: 2025-02-18T05:05:34.852313
    Row count: 4
    Null count: 0 (0.0%)
    Unique values: 4
    Min value: 75.00
    Max value: 200.00
    Mean value: 131.25
    Std dev: 55.43

    TRANSACTIONS:
    Timestamp: 2025-02-18T05:05:36.576349
    Row count: 4
    Null count: 0 (0.0%)
    Unique values: 4
    Min value: 1.00
    Max value: 4.00
    Mean value: 2.50
    Std dev: 1.29

    SESSION_LENGTH:
    Timestamp: 2025-02-18T05:05:38.475332
    Row count: 4
    Null count: 0 (0.0%)
    Unique values: 3
    Min value: 0.00
    Max value: 45.20
    Mean value: 18.93
    Std dev: 22.66

    SUM_AMOUNT_2:
    Timestamp: 2025-02-18T05:05:39.955529
    Row count: 4
    Null count: 0 (0.0%)
    Unique values: 4
    Min value: 75.00
    Max value: 275.00
    Mean value: 175.00
    Std dev: 102.06

    AVG_AMOUNT_2:
    Timestamp: 2025-02-18T05:05:41.388139
    Row count: 4
    Null count: 0 (0.0%)
    Unique values: 4
    Min value: 75.00
    Max value: 137.50
    Mean value: 109.38
    Std dev: 27.72

    Training Data Schema:
    CUSTOMER_ID: StringType()
    DATE: DateType()
    AMOUNT: DoubleType()
    TRANSACTIONS: LongType()
    SESSION_LENGTH: DoubleType()
    SUM_AMOUNT_2: DoubleType()
    AVG_AMOUNT_2: DoubleType()
    2025-02-17 21:06:02,055 - snowflake_feature_store - INFO - Cleaned up schema FEATURE_STORE_20250218_050511_c9c725ea
