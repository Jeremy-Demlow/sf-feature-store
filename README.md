# Snowflake Feature Store


<!-- WARNING: THIS FILE WAS AUTOGENERATED! DO NOT EDIT! -->

# Snowflake Feature Store

> A comprehensive toolkit for building and managing ML features in
> Snowflake, with focus on LTV prediction.

## What is this?

This library provides a production-ready interface to Snowflake’s
Feature Store, enabling you to: 1. Create and manage feature
transformations with validation 2. Handle temporal features and windowed
aggregations 3. Generate point-in-time correct training datasets 4.
Monitor feature quality and detect drift 5. Maintain feature
documentation and versioning

## Install

``` bash
pip install snowflake-feature-store
```

## How to use

### Complete LTV Example

Here’s a full example of setting up a feature store for LTV prediction:

``` python
from snowflake_feature_store.connection import get_connection
from snowflake_feature_store.manager import feature_store_session 
from snowflake_feature_store.config import ( FeatureViewConfig, FeatureConfig, FeatureValidationConfig )

Connect to Snowflake
conn = get_connection()

Create feature store session
with feature_store_session(conn, cleanup=False) as manager: # 1. Create Customer Entity manager.add_entity( name="CUSTOMER", join_keys=["CUSTOMER_ID"], description="Customer entity for LTV prediction" )

# 2. Configure Features
feature_configs = {
    "LIFE_TIME_VALUE": FeatureConfig(
        name="LIFE_TIME_VALUE",
        description="Current customer value",
        validation=FeatureValidationConfig(
            null_threshold=0.1,
            range_check=True,
            min_value=0
        )
    ),
    "SESSION_LENGTH": FeatureConfig(
        name="SESSION_LENGTH",
        description="Session duration in minutes",
        validation=FeatureValidationConfig(
            null_threshold=0.3,
            range_check=True,
            min_value=0
        )
    )
}

# 3. Create Feature View
config = FeatureViewConfig(
    name="customer_behavior",
    domain="RETAIL",
    entity="CUSTOMER",
    feature_type="BEHAVIOR",
    features=feature_configs,
    refresh=RefreshConfig(frequency="1 day")
)

# 4. Add Transformations
transforms = [
    fill_na(['SESSION_LENGTH'], 0),
    moving_agg(
        cols=['TRANSACTIONS'],
        window_sizes=[7, 30],
        agg_funcs=['SUM', 'AVG'],
        partition_by=['CUSTOMER_ID'],
        order_by=['DATE']
    )
]

# 5. Create Feature View
feature_view = manager.add_feature_view(
    config=config,
    df=source_df,
    entity_name="CUSTOMER",
    transforms=transforms
)

# 6. Generate Training Data
training_data = generate_ltv_training_data(
    manager=manager,
    feature_view=feature_view,
    training_start_date='2024-01-01',
    training_end_date='2024-03-01',
    prediction_window=90
)
```

### Key Components

1.  **Feature Configuration**
    - Validation rules
    - Data quality checks
    - Documentation
    - Dependencies
2.  **Transformations**
    - Missing value handling
    - Window aggregations
    - Custom transforms
    - Feature combination
3.  **Monitoring**
    - Feature statistics
    - Drift detection
    - Quality metrics
    - Alert configuration
4.  **Training Data**
    - Point-in-time correctness
    - Label generation
    - Feature selection
    - Data validation

## Documentation

The library includes detailed documentation for each component:

1.  [Connection Management](./01_connection.ipynb): Snowflake connection
    setup and management
2.  [Feature Transforms](./02_transforms.ipynb): Feature engineering and
    validation
3.  [Feature Views](./03_feature_view.ipynb): Feature organization and
    versioning
4.  [Feature Store](./04_manager.ipynb): Feature store operations and
    monitoring
5.  [End-to-End Example](./06_simple_example.ipynb): Complete LTV
    prediction workflow

## Advanced Features

1.  **Feature Monitoring**

``` python
# Monitor feature drift
monitor = LTVMonitor(manager, feature_view.name) 
monitor.set_baseline(feature_view.feature_df) 
drift_metrics = monitor.check_feature_health(new_data)
```

2.  **Custom Transformations**

``` python
# Create custom transform
@transform_config(name="engagement_score")
def calculate_engagement(df): 
    return df.with_column( 'ENGAGEMENT_SCORE', (F.col('SESSION_LENGTH') + F.col('TIME_ON_APP')) / 2.0 )
```

3.  **Point-in-Time Training**

``` python
# Generate training data create a function like this
training_data = generate_ltv_training_data( manager=manager, feature_view=feature_view, training_start_date='2024-01-01', prediction_window=90 )
```

### Installation

Install latest from the GitHub
[repository](https://github.com/Jeremy-Demlow/sf-feature-store):

``` sh
$ pip install git+https://github.com/Jeremy-Demlow/sf-feature-store.git
```

or from [pypi](https://pypi.org/project/sf-feature-store/)

``` sh
$ pip install sf_feature_store
```
